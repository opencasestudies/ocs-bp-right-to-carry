---
title: "Right-to-carry Case Study"
author: "Michael Ontiveros, Carrie Wright, PhD."
date: "4/16/2020"
output: 
    html_document:
        theme: cosmo 
        toc: true
        toc_float: true
        highlight: tango
        number_sections: false
---

# RA Notes

## Literature

This case study will focus on conflicting findings from two papers.

[Donohue, et al.](https://www.nber.org/papers/w23510.pdf)

[Lott and Mustard](https://chicagounbound.uchicago.edu/cgi/viewcontent.cgi?article=1150&context=law_and_economics)

## Question

How does the inclusion of different numbers of age groups influence the results of an analysis of right to carry laws and violence rates?

## Description

We will evaluate how multicollinearity can influence linear regression results and resulted in different conclusions for Donohoe vs Lott on this very important topic. 

## Data Sources

# Motivation

## Background

It is important that we do not treat race as an objective measure. Despite this, it can be used to advance scientific inquiry. For more information on this topic, we have included a link to a [paper on the use of race as a measure in epidemiology](https://academic.oup.com/epirev/article/22/2/187/456942). 

How does the inclusion of different numbers of age groups influence the results of an analysis of right to carry laws and violence rates?

## Table 2, Donohue, et al. 

**This screenshot needs to be taken again. Cursor highlight is showing**

```{r, echo=FALSE, out.height = '100%', out.width = '100%', fig.align='center'}
knitr::include_graphics('Donohue_Table2.png')
```

```{r, echo=FALSE, out.height = '75%', out.width = '75%', fig.align='center'}
knitr::include_graphics('Educational_Graphic1.jpg')
```

## Analysis goal

We will evaluate how multicollinearity can influence linear regression results and result in different conclusions for Donohoe vs Lott on this very important topic. We will also discuss briefly how synthetic control methods can be used to assess the impact of policies by creating controls for comparison that did not have policy adoption but were otherwise similar.

This analysis will demonstrate how details about our methods can be critically influential for our overall conclusions  and can result in important policy related consequences. This report will provide a basis for the motivation:  https://www.nber.org/papers/w23510. As this is a historically controversial topic, we will focus on how different statistical methods can yield different results, but we will avoid making conclusions about right to carry laws.

```{r, echo=FALSE, out.height = '75%', out.width = '75%', fig.align='center'}
knitr::include_graphics('Educational_Graphic2.jpg')
```

## Learning objectives

Linear regression analysis, directed acyclic graphs, discussion about the influence of multicollinearity

1) wrangling – joining data from multiple sources (dplyr)  and data reshaping (tidyr)
2) visualizations (ggplot2)

## Libraries

```{r}
library(car) # vif function
library(MASS) # negative binomial regression
library(plm)
library(broom) # tidy output
library(tidyverse) # general wrangling functions
library(pdftools) # read data from pdf 
library(readxl) # importing excel sheets
library(ggdag) # DAGs
library(cowplot) # to produce plot of plots 
```

# What is the data?

## Appendix J, Donohue, et al.

Below is table from the [Donohue, et al.](https://www.nber.org/papers/w23510.pdf) paper.

The datasets below were available to the respective authors at the time of their analyses. 

```{r, echo=FALSE, out.height = '100%', out.width = '100%', fig.align='center'}
knitr::include_graphics('Donohue_AppendixJ.png')
```

# Data import 

# Causal Inference

<style>
div.red { background-color:#ffcccc; border-radius: 5px; padding: 20px;}
</style>
<div class = "red">
DISCLAIMER: The content in this case study was created solely for demonstrative purposes. Resultantly, the relationships shown may not be accurate.
</div>

## Directed acyclic graphs

[**D**irected **A**cyclic **G**raphs](https://en.wikipedia.org/wiki/Directed_acyclic_graph?oldformat=true) are often used to identify adjustment sets, the sets of variables that need to be controlled for in an analysis.

Arrows stemming from one variable to another represent causal relationships between the two. The paths of arrows never create a cycle. The relationships between the variables for a [graph](https://www.wikiwand.com/en/Graph_(discrete_mathematics). These, altogether, for a directed acyclic graph. 

In scientific inquiry, directed acyclic graphs—as visual representations of the world—rarely encompass all relationships relevant to a question. Still, they are helpful at identifying flaws in our analytic methods. 

Below is a labelled directed acyclic graph.

```{r, echo=FALSE}
COORDSX_1 <- tibble::tribble(
  ~name, ~x, ~y,
  "Y", 2, 0,
  "X", 1, 0,
  "A", 1.5, 2,
  "B", 1.5, 0,
  "C", 1.5, -2,
  "R", 1, -2,
  "S", 2, 2
)

DAGX_1 <- dagify(Y ~ A + S,
               X ~ A + R, 
               Y ~ B,
               B ~ X,
               C ~ Y,
               C ~ X,
       exposure = "X",
       outcome = "Y",
       coords = COORDSX_1) %>%
  tidy_dagitty(seed = 1) %>%
  ggdag(text = TRUE,
        node = FALSE,
        text_col = "black",
        text_size = 8) +
  xlim(c(0.5,2.5)) +
  ylim(c(-2.5,2.5)) +
  labs(title = "Variables that can be found of a directed acyclic graph",
       subtitle = "X: Exposure\nY: Outcome\nA: Confounder\nB: Mediator\nC: Collider\nR: Instrument\nS: Extraneous variable associated only with outcome") +
  theme_void()

DAGX_1
```

Below is a directed acyclic graph for the analysis we will conduct. 

```{r, echo=FALSE}
set.seed(999)

COORDS1 <- tibble::tribble(
  ~name, ~x, ~y,
  "Crime", 2, 0,
  "Law", 1, 0,
  "Demographics", 1.5, 2,
  "Alcohol", 1.75, 1,
  "Unemployment", 1.5, -2,
  "Poverty", 1.5, -1,
  "Police", 2, 2
)

DAG1 <- dagify(Crime ~ Law + Alcohol + Unemployment + Poverty + Police,
               Law ~ Demographics + Unemployment + Poverty, 
               Alcohol ~ Demographics,
               Poverty ~ Unemployment,
       exposure = "Law",
       outcome = "Crime",
       coords = COORDS1) %>%
  tidy_dagitty(seed = 1) %>%
  ggdag(text = TRUE,
        node = FALSE,
        text_col = "black",
        text_size = 4) +
  xlim(c(0.5,2.5)) +
  ylim(c(-2.5,2.5)) +
  labs(title = "Directed acyclic graph",
       subtitle = "We will assume this represents the mechanisms relevant to our question.") +
  theme_void()

DAG1
```

## Identifying Adjustment Sets

Below we list a set of general rules for identifying adjustment sets in causal inference. These rules, while not exhaustive, provide a general framework for identifying adjustment sets with directed acyclic graphs

<style>
div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 20px;}
</style>
<div class = "blue">
**Rules for causal inference adjustment sets**

1. Confounders should be adjusted for
2. Instruments should not be adjusted for
5. Extraneous variables only associated with outcome should be adjusted for
3. Mediators should not be adjusted for 
4. Colliders block paths

**Gather information from the directed acyclic graph**

1. List each pathway 
2. Label each pathway as causal or non-causal
3. Label each pathway as open or closed
4. Identify important variable types
    + Exposure
    + Outcome
    + Instruments
    + Extraneous variables associated only with outcome
    + Colliders
    + Mediators
    + Confounders
5. Identify variables that can be adjusted for to block open, non-causal pathways
</div>

Let's see how we can use a DAG to guide our analysis.

To get acquainted with how DAGs work, we will explore each pathway and make some comments on relationships we see. After exploring each pathway, we will use the rules above to define our adjustment set. 

```{r, echo=FALSE}
DAG1_explain <- dagify(Crime ~ Law + Alcohol + Unemployment + Poverty + Police,
               Law ~ Demographics + Unemployment + Poverty, 
               Alcohol ~ Demographics,
               Poverty ~ Unemployment,
       exposure = "Law",
       outcome = "Crime",
       coords = COORDS1) %>%
  tidy_dagitty(seed = 1) %>%
  ggdag(text = TRUE,
        node = FALSE,
        text_col = "black",
        text_size = 4) +
  xlim(c(0.5,2.5)) +
  ylim(c(-2.5,2.5)) +
  theme_void()

DAG1_explain
```

This is the caual path we are interested in evaluating. As a causal path, we want to make sure this path is left open.

```{r, echo=FALSE}
CP1_1 <- dagify(Crime ~ Law,
       exposure = "Law",
       outcome = "Crime",
       coords = COORDS1) %>%
  tidy_dagitty() %>%
  ggdag(text = TRUE,
        node = FALSE,
        text_col = "black",
        text_size = 4) +
  xlim(c(0.5,2.5)) +
  ylim(c(-2.5,2.5)) +
  theme_void()

CP1_1 
```

This is a non-causal pathway. Alcohol consumption is a mediator on the pathway between demographics and the outcome meaning that, in the absense of any other relationships we should account for, we do not have have to control for it in our analysis. We can ignore the alcohol variable altogether in our analysis since the alcohol variable is a mediator on this pathway with no relationships to other variables. With that said, the demographics variable is a confounder; this variable must be adjusted for if we wish to close this pathway.

```{r, echo=FALSE}
NCP1_1 <- dagify(Crime ~ Alcohol,
                 Alcohol ~ Demographics,
                 Law ~ Demographics,
                 exposure = "Law",
                 outcome = "Crime",
                 coords = COORDS1) %>%
  tidy_dagitty() %>%
  ggdag(text = TRUE,
        node = FALSE,
        text_col = "black",
        text_size = 4) +
  xlim(c(0.5,2.5)) +
  ylim(c(-2.5,2.5)) +
  theme_void()

NCP1_1
```

This pathway is an open, non-causal pathway. The poverty variable influences both the exposure and outcome. This makes the variable a confounder. No other variables are in this pathway. We should close this pathway by adjusting for poverty. 

```{r, echo=FALSE}
NCP1_2 <- dagify(Crime ~ Poverty,
                 Law ~ Poverty,
                 exposure = "Law",
                 outcome = "Crime",
                 coords = COORDS1) %>%
  tidy_dagitty() %>%
  ggdag(text = TRUE,
        node = FALSE,
        text_col = "black",
        text_size = 4) +
  xlim(c(0.5,2.5)) +
  ylim(c(-2.5,2.5)) +
  theme_void()

NCP1_2
```

This pathway is very similar to the pathway describe above. 

This pathway is an open, non-causal pathway. The unemployment variable influences both the exposure and outcome. This makes the variable a confounder. No other variables are in this pathway. We should close this pathway by adjusting for unemployment. 

```{r, echo=FALSE}
NCP1_3 <- dagify(Crime ~ Unemployment,
                 Law ~ Unemployment,
                 exposure = "Law",
                 outcome = "Crime",
                 coords = COORDS1) %>%
  tidy_dagitty() %>%
  ggdag(text = TRUE,
        node = FALSE,
        text_col = "black",
        text_size = 4) +
  xlim(c(0.5,2.5)) +
  ylim(c(-2.5,2.5)) +
  theme_void()

NCP1_3
```

This is a non-causal pathway. Poverty is a mediator on the pathway between the unemployment variable and the outcome meaning that, in the absense of any other relationships we should account for, we do not have have to control for it in our analysis. Unlike the alcohol variable, we can not yet ignore the poverty variable altogether in our analysis since the variable has a relationship with another variable, our exposure. With that said, the unemployment variable is a confounder; this variable must be adjusted for if we wish to close this pathway.

```{r, echo=FALSE}
NCP1_4 <- dagify(Crime ~  Poverty,
                 Poverty ~ Unemployment,
                 Law ~ Unemployment,
                 exposure = "Law",
                 outcome = "Crime",
                 coords = COORDS1) %>%
  tidy_dagitty() %>%
  ggdag(text = TRUE,
        node = FALSE,
        text_col = "black",
        text_size = 4) +
  xlim(c(0.5,2.5)) +
  ylim(c(-2.5,2.5)) +
  theme_void()

NCP1_4
```

This is a non-causal pathway. The police variable only influences the outcome. Adjusting for this variable may increase the precision of our estimate. 

```{r}
NCP1_5 <- dagify(Crime ~ Police + Law,
                 exposure = "Law",
                 outcome = "Crime",
                 coords = COORDS1) %>%
  tidy_dagitty() %>%
  ggdag(text = TRUE,
        node = FALSE,
        text_col = "black",
        text_size = 4) +
  xlim(c(0.5,2.5)) +
  ylim(c(-2.5,2.5)) +
  theme_void()

NCP1_5
```

Click [here to learn more about biases introduced by adjustment ](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2744485/), [here to learn more about the consequences instrumental variable adjustment](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3254160/), or [here to learn about M-bias and butterfly bias](https://arxiv.org/abs/1408.0324#:~:text=%22M%2DBias%2C%22%20as,when%20the%20treatment%20and%20the).

# Data wrangling

## Variables

### State FIPS codes

The following data was downloaded from the [US Census Bureau](https://www.census.gov/geographies/reference-files/2014/demo/popest/2014-geocodes-state.html)

```{r}
STATE_FIPS <- read_xls("Data/State_FIPS_codes/state-geocodes-v2014.xls", skip = 5)

head(STATE_FIPS)

colnames(STATE_FIPS) <- c("Region",
                          "Division",
                          "STATEFP",
                          "STATE")

class(STATE_FIPS$STATEFP)

STATE_FIPS <- STATE_FIPS %>%
    filter(STATEFP!="00") %>%
    dplyr::select(STATEFP, STATE)
```

### Demographics

#### 1977-1979

The following data was downloaded from the [US Census Bureau](https://www2.census.gov/programs-surveys/popest/tables/1900-1980/state/asrh/).

```{r}
dem_77_79 <- read_csv("Data/Demographics/Decade_1970/pe-19.csv", skip = 5)

head(dem_77_79)

colnames(dem_77_79)

class(dem_77_79$`Year of Estimate`)

dem_77_79 <- dem_77_79 %>%
  mutate(RACE = case_when(str_detect(`Race/Sex Indicator`,"Black") ~ "Black",
                          str_detect(`Race/Sex Indicator`,"White") ~ "White",
                          TRUE ~ "Other"),
         SEX = case_when(str_detect(`Race/Sex Indicator`,"female") ~ "Female",
                         TRUE ~ "Male")) %>%
  dplyr::select(-`Race/Sex Indicator`,-`FIPS State Code`)

dem_77_79 <- dem_77_79 %>%
    rename("YEAR"=`Year of Estimate`,
           "STATE"=`State Name`) %>%
    filter(YEAR %in% 1977:1979)
    
dem_77_79 <- dem_77_79 %>%
  pivot_longer(cols=contains("years"),
               names_to = "AGE_GROUP",
               values_to = "SUB_POP")

colnames(dem_77_79)

pop_77_79 <- dem_77_79 %>%
  group_by(YEAR, STATE) %>%
  summarise("TOT_POP" = sum(SUB_POP), .groups = "drop") 

colnames(pop_77_79)

dem_77_79 <- dem_77_79 %>%
  left_join(pop_77_79, by = c("YEAR","STATE")) %>%
  mutate(PERC_SUB_POP = SUB_POP*100/TOT_POP) %>%
  dplyr::select(-SUB_POP, -TOT_POP)
```

#### 1980-1989

The following data was downloaded from the [US Census Bureau](https://www2.census.gov/programs-surveys/popest/tables/1980-1990/counties/asrh/).

County data was used for this decade. 

```{r}
dem_80_89 <- list.files(recursive = TRUE,
                  path = "Data/Demographics/Decade_1980/",
                  pattern = "*.csv",
                  full.names = TRUE) %>% 
  map(~read_csv(., skip=5))

dem_80_89 <- dem_80_89 %>%
  map_df(bind_rows)

sapply(dem_80_89, class)

dem_80_89 <- dem_80_89 %>%
  mutate(RACE = case_when(str_detect(`Race/Sex Indicator`,"Black") ~ "Black",
                          str_detect(`Race/Sex Indicator`,"White") ~ "White",
                          TRUE ~ "Other"),
         SEX = case_when(str_detect(`Race/Sex Indicator`,"female") ~ "Female",
                         TRUE ~ "Male")) %>%
  dplyr::select(-`Race/Sex Indicator`)

colnames(dem_80_89)

dem_80_89 <- dem_80_89 %>% 
    rename("YEAR"=`Year of Estimate`,
           "STATEFP_temp"=`FIPS State and County Codes`) %>%
    mutate(STATEFP = substr(STATEFP_temp, start = 1, stop = 2)) %>%
    left_join(STATE_FIPS, by = "STATEFP") %>%
  dplyr::select(-STATEFP)

dem_80_89 <- dem_80_89 %>%
  pivot_longer(cols=contains("years"),
               names_to = "AGE_GROUP",
               values_to = "SUB_POP_temp") %>%
  group_by(YEAR, STATE, AGE_GROUP, SEX, RACE) %>%
  summarise(SUB_POP = sum(SUB_POP_temp), .groups="drop")
  
colnames(dem_80_89)

pop_80_89 <- dem_80_89 %>%
  group_by(YEAR, STATE) %>%
  summarise("TOT_POP" = sum(SUB_POP), .groups = "drop") 

colnames(pop_80_89)

dem_80_89 <- dem_80_89 %>%
  left_join(pop_80_89, by = c("YEAR","STATE")) %>%
  mutate(PERC_SUB_POP = SUB_POP*100/TOT_POP) %>%
  dplyr::select(-SUB_POP, -TOT_POP)
```

#### 1990-1999

The following data was downloaded from the [US Census Bureau](https://www2.census.gov/programs-surveys/popest/tables/1990-2000/state/asrh/).

```{r}
dem_90_99 <- list.files(recursive = TRUE,
                  path = "Data/Demographics/Decade_1990/",
                  pattern = "*.txt",
                  full.names = TRUE) %>% 
  map(~read_table2(., skip = 14))

dem_90_99_names <- list.files(recursive = TRUE,
                  path = "Data/Demographics/Decade_1990/",
                  pattern = "*.txt") %>%
    str_extract("[9][0-9]") %>%
    paste0("Year_19",.)

dem_90_99 <- dem_90_99 %>%
  map_df(bind_rows)

colnames(dem_90_99)

head(dem_90_99)

colnames(dem_90_99) <- c("YEAR",
                         "STATEFP",
                         "Age",
                         "NH_W_M",
                         "NH_W_F",
                         "NH_B_M",
                         "NH_B_F",
                         "NH_AIAN_M",
                         "NH_AIAN_F",
                         "NH_API_M",
                         "NH_API_F",
                         "H_W_M",
                         "H_W_F",
                         "H_B_M",
                         "H_B_F",
                         "H_AIAN_M",
                         "H_AIAN_F",
                         "H_API_M",
                         "H_API_F")

dim(dem_90_99)

dem_90_99 <- dem_90_99 %>%
    mutate(W_M = NH_W_M + H_W_M,
           W_F = NH_W_F + H_W_F,
           B_M = NH_B_M + H_B_M,
           B_F = NH_B_F + H_B_F,
           AIAN_M = NH_AIAN_M + H_AIAN_M,
           AIAN_F = NH_AIAN_F + H_AIAN_F,
           API_M = NH_API_M + H_API_M,
           API_F = NH_API_F + H_API_F,
           n_na = rowSums(is.na(.))) %>%
  dplyr::select(-starts_with("NH_"), -starts_with("H_"))

dem_90_99 %>%
  group_by(n_na) %>%
  tally()

empty_rows_na <- dem_90_99 %>%
  group_by(n_na) %>%
  tally() %>%
  filter(n_na != 0) %>%
  pull(n_na)

dem_90_99 <- dem_90_99 %>%
  filter(n_na != empty_rows_na) %>%
  dplyr::select(-n_na)

sapply(dem_90_99, class)

summary(as.factor(dem_80_89$AGE_GROUP))

dem_90_99 <- dem_90_99 %>%
  mutate(AGE_GROUP = cut(Age,
                         breaks = seq(0,90, by=5),
                         right = FALSE,
                         labels = c("Under 5 years",
                                    "5 to 9 years",
                                    "10 to 14 years",
                                    "15 to 19 years",
                                    "20 to 24 years",
                                    "25 to 29 years",
                                    "30 to 34 years",
                                    "35 to 39 years",
                                    "40 to 44 years",
                                    "45 to 49 years",
                                    "50 to 54 years",
                                    "55 to 59 years",
                                    "60 to 64 years",
                                    "65 to 69 years",
                                    "70 to 74 years",
                                    "75 to 79 years",
                                    "80 to 84 years",
                                    "85 years and over")
                         )) %>%
  dplyr::select(-Age) %>%
  mutate(AGE_GROUP = as.character(AGE_GROUP))

sapply(dem_90_99, class)

dem_90_99 <- dem_90_99 %>%
  group_by(YEAR, STATEFP, AGE_GROUP) %>%
  summarise_at(vars(starts_with("W_"),
                    starts_with("B_"),
                    starts_with("AIAN_"),
                    starts_with("API_")), sum) %>%
  ungroup() %>%
  pivot_longer(cols = c(starts_with("W_"),
                    starts_with("B_"),
                    starts_with("AIAN_"),
                    starts_with("API_")),
               names_to = "RACE",
               values_to = "SUB_POP")

dem_90_99 <- dem_90_99 %>%
  mutate(SEX = case_when(str_detect(RACE, "_M") ~ "Male",
                         TRUE ~ "Female"),
         RACE = case_when(str_detect(RACE, "W_") ~ "White",
                          str_detect(RACE, "B_") ~ "Black",
                          TRUE ~ "Other")) %>%
  left_join(STATE_FIPS, by = "STATEFP") %>%
  dplyr::select(-STATEFP)

pop_90_99 <- dem_90_99 %>%
  group_by(YEAR, STATE) %>%
  summarise(TOT_POP = sum(SUB_POP), .groups = "drop")

dem_90_99 <- dem_90_99 %>%
  left_join(pop_90_99, by=c("YEAR", "STATE")) %>%
  mutate(PERC_SUB_POP = SUB_POP*100/TOT_POP) %>%
  dplyr::select(-SUB_POP, -TOT_POP)
```

#### 2000-2010

The following data was downloaded from the [US Census Bureau](https://www.census.gov/data/datasets/time-series/demo/popest/intercensal-2000-2010-state.html).

[Click here for relevant technical documentation](https://www2.census.gov/programs-surveys/popest/technical-documentation/file-layouts/2000-2010/intercensal/state/st-est00int-alldata.pdf)

```{r}
dem_00_10 <- list.files(recursive = TRUE,
                  path = "Data/Demographics/Decade_2000/",
                  pattern = "*.csv",
                  full.names = TRUE) %>% 
  map(~read_csv(.))

dem_00_10 <- dem_00_10 %>%
  map_df(bind_rows)

sapply(dem_00_10, class)

dem_00_10 <- dem_00_10 %>%
  dplyr::select(-ESTIMATESBASE2000,-CENSUS2010POP) %>%
  filter(REGION != 0,
         DIVISION != 0,
         SEX != 0,
         ORIGIN == 0,
         RACE != 0,
         AGEGRP != 0,
         STATE != 0) %>%
  dplyr::select(-REGION, -DIVISION, -ORIGIN, -STATE) %>%
  rename("STATE"=NAME,
         "AGE_GROUP"=AGEGRP) %>%
  mutate(SEX = factor(SEX,
                            levels = 1:2,
                            labels = c("Male",
                                    "Female")),
         RACE = factor(RACE,
                            levels = 1:6,
                            labels = c("White",
                                    "Black",
                                    rep("Other",4))),
         AGE_GROUP = factor(AGE_GROUP,
                            levels = 1:18,
                            labels = c("Under 5 years",
                                    "5 to 9 years",
                                    "10 to 14 years",
                                    "15 to 19 years",
                                    "20 to 24 years",
                                    "25 to 29 years",
                                    "30 to 34 years",
                                    "35 to 39 years",
                                    "40 to 44 years",
                                    "45 to 49 years",
                                    "50 to 54 years",
                                    "55 to 59 years",
                                    "60 to 64 years",
                                    "65 to 69 years",
                                    "70 to 74 years",
                                    "75 to 79 years",
                                    "80 to 84 years",
                                    "85 years and over"))) %>%
  mutate(SEX = as.character(SEX),
         RACE = as.character(RACE),
         AGE_GROUP = as.character(AGE_GROUP))
  
colnames(dem_00_10)

dem_00_10 <- dem_00_10 %>%
  pivot_longer(cols=contains("ESTIMATE"),
               names_to = "YEAR",
               values_to = "SUB_POP")

dem_00_10 <- dem_00_10 %>%
  mutate(YEAR = str_sub(YEAR, start=-4)) %>%
  mutate(YEAR = as.numeric(YEAR))

sapply(dem_00_10, class)

pop_00_10 <- dem_00_10 %>%
  group_by(YEAR, STATE) %>%
  summarise(TOT_POP = sum(SUB_POP), .groups = "drop")

dem_00_10 %>%
  left_join(pop_00_10, by=c("YEAR", "STATE")) %>%
  group_by(YEAR, STATE) %>%
  mutate(PERC_SUB_POP = SUB_POP*100/TOT_POP) %>%
  summarise(perc_tot = sum(PERC_SUB_POP), .groups = "drop") %>%
  mutate(poss_error = case_when(abs(perc_tot - 100) > 0 ~ TRUE, 
                                TRUE ~ FALSE)) %>%
  group_by(poss_error) %>%
  tally()

dem_00_10 <- dem_00_10 %>%
  left_join(pop_00_10, by=c("YEAR", "STATE")) %>%
  mutate(PERC_SUB_POP = SUB_POP*100/TOT_POP) %>%
  dplyr::select(-SUB_POP, -TOT_POP)
```

#### 1977 - 2010

```{r}
setequal(colnames(dem_77_79),colnames(dem_80_89))
setequal(colnames(dem_80_89),colnames(dem_90_99))
setequal(colnames(dem_90_99),colnames(dem_00_10))

head(dem_77_79)
head(dem_80_89)
head(dem_90_99)
head(dem_00_10)

length(summary(as.factor(dem_77_79$AGE_GROUP)))
length(summary(as.factor(dem_80_89$AGE_GROUP)))
length(summary(as.factor(dem_90_99$AGE_GROUP)))
length(summary(as.factor(dem_00_10$AGE_GROUP)))

dem <- bind_rows(dem_77_79,
                 dem_80_89,
                 dem_90_99,
                 dem_00_10)
  
dem %>%
  filter(RACE == "Other") %>%
  group_by(YEAR) %>%
  tally() %>%
  summarise(years_data = n())

2010 - 1977 + 1
  
DONOHUE_AGE_GROUPS <- c("15 to 19 years",
                        "20 to 24 years",
                        "25 to 29 years",
                        "30 to 34 years",
                        "35 to 39 years")

DONOHUE_RACE <- c("White",
                  "Black",
                  "Other")

DONOHUE_SEX <- c("Male")

dem_DONOHUE <- dem %>%
  filter(AGE_GROUP %in% DONOHUE_AGE_GROUPS,
         RACE %in% DONOHUE_RACE,
         SEX %in% DONOHUE_SEX) %>%
  mutate(AGE_GROUP = fct_collapse(AGE_GROUP, "20 to 39 years"=c("20 to 24 years",
                                                                "25 to 29 years",
                                                                "30 to 34 years",
                                                                "35 to 39 years"))) %>%
  mutate(AGE_GROUP = str_replace_all(AGE_GROUP," ","_")) %>%
  group_by(YEAR, STATE, RACE, SEX, AGE_GROUP) %>%
  summarise(PERC_SUB_POP = sum(PERC_SUB_POP), .groups = "drop") %>%
  unite(col = "VARIABLE", RACE, SEX, AGE_GROUP, sep = "_") %>%
  rename("VALUE"=PERC_SUB_POP)

LOTT_AGE_GROUPS_NULL <- c("Under 5 years",
                          "5 to 9 years")

LOTT_RACE <- c("White",
               "Black",
               "Other")

LOTT_SEX <- c("Male",
              "Female")

dem_LOTT <- dem %>%
  filter(!(AGE_GROUP %in% LOTT_AGE_GROUPS_NULL),
         RACE %in% LOTT_RACE,
         SEX %in% LOTT_SEX) %>%
  mutate(AGE_GROUP = fct_collapse(AGE_GROUP,
                                  "10 to 19 years"=c("10 to 14 years",
                                                     "15 to 19 years"),
                                  "20 to 29 years"=c("20 to 24 years",
                                                     "25 to 29 years"),
                                  "30 to 39 years"=c("30 to 34 years",
                                                     "35 to 39 years"),
                                  "40 to 49 years"=c("40 to 44 years",
                                                     "45 to 49 years"),
                                  "50 to 64 years"=c("50 to 54 years",
                                                     "55 to 59 years",
                                                     "60 to 64 years"),
                                  "65 years and over"=c("65 to 69 years",
                                                        "70 to 74 years",
                                                        "75 to 79 years",
                                                        "80 to 84 years",
                                                        "85 years and over"))) %>%
  mutate(AGE_GROUP = str_replace_all(AGE_GROUP," ","_")) %>%
  group_by(YEAR, STATE, RACE, SEX, AGE_GROUP) %>%
  summarise(PERC_SUB_POP = sum(PERC_SUB_POP), .groups = "drop") %>%
  unite(col = "VARIABLE", RACE, SEX, AGE_GROUP, sep = "_") %>%
  rename("VALUE"=PERC_SUB_POP)
  
dim(expand.grid(c(1:6), c(7:8), c(9:10)))[1]
```

```{r}
setequal(colnames(pop_77_79),colnames(pop_80_89))
setequal(colnames(pop_80_89),colnames(pop_90_99))
setequal(colnames(pop_90_99),colnames(pop_00_10))

head(pop_77_79)
head(pop_80_89)
head(pop_90_99)
head(pop_00_10)

population_data <- bind_rows(pop_77_79,
                             pop_80_89,
                             pop_90_99,
                             pop_00_10)

population_data %>%
  group_by(YEAR) %>%
  tally() %>%
  print(n = dim(.)[1])

population_data <- population_data %>%
  mutate(VARIABLE = "Population") %>%
  rename("VALUE"=TOT_POP)
```

### Police staffing

The following data was downloaded from the [Federal Bureau of Investigation](https://crime-data-explorer.fr.cloud.gov/downloads-and-docs).

```{r}
ps_data <- read_csv("Data/Police_staffing/pe_1960_2018.csv",
                    col_types = cols(male_total_ct = "n",
                                     female_total_ct = "n"))

colnames(ps_data)

ps_data <- ps_data %>%
  filter(data_year >= 1977, 
         data_year <= 2014) %>%
  mutate(male_total_ct = case_when(is.na(male_total_ct) ~ 0,
                                   TRUE ~ male_total_ct),
         female_total_ct = case_when(is.na(female_total_ct) ~ 0,
                                   TRUE ~ female_total_ct)) %>%
  mutate(officer_total = male_total_ct + female_total_ct) %>%
  dplyr::select(data_year,
                pub_agency_name,
                state_abbr,
                officer_total)

ps_data <- ps_data %>%
  group_by(data_year, state_abbr) %>%
  summarise(officer_state_total=sum(officer_total), .groups = "drop")

ps_data %>%
  group_by(state_abbr) %>%
  tally() %>%
  print(n = dim(.)[1])

# NB is Nebraska. This was changed to NE to avoid confusions with NB in Canada. This dataset uses NB

state_of_interest_NULL <- c("AS",
                            "GM",
                            "CZ",
                            "FS",
                            "MP",
                            "OT",
                            "PR",
                            "VI")

state_abb_df <- as.data.frame(cbind(state.abb, state.name))

colnames(state_abb_df) <- c("state_abbr", "STATE")

print(state_abb_df)

state_abb_df <- state_abb_df %>%
  add_row(state_abbr="DC",
          STATE="District of Columbia")

denominator_temp <- population_data %>%
  dplyr::select(-VARIABLE) %>%
  rename("Population_temp"=VALUE)

ps_data <- ps_data %>%
  filter(!(state_abbr %in% state_of_interest_NULL)) %>%
  mutate(state_abbr = case_when(state_abbr == "NB" ~ "NE",
                                TRUE ~ state_abbr)) %>%
  left_join(state_abb_df, by = "state_abbr") %>%
  dplyr::select(-state_abbr) %>%
  rename(YEAR = "data_year",
         VALUE = "officer_state_total") %>%
  mutate(VARIABLE = "officer_state_total") %>%
  left_join(denominator_temp, by=c("STATE","YEAR")) %>%
  mutate(VALUE = (VALUE*100000) / Population_temp) %>%
  mutate(VALUE = lag(VALUE)) %>%
  mutate(VARIABLE = "police_per_100k_lag") %>%
  dplyr::select(-Population_temp)
```

### Unemployment

https://data.bls.gov/cgi-bin/dsrv?la

```{r}
ue_rate_data <- list.files(recursive = TRUE,
                  path = "Data/Unemployment",
                  pattern = "*.xlsx",
                  full.names = TRUE) %>% 
  map(~read_xlsx(., skip = 10))

ue_rate_names <- list.files(recursive = TRUE,
                  path = "Data/Unemployment",
                  pattern = "*.xlsx",
                  full.names = TRUE) %>%
  map(~read_xlsx(.)) %>%
  sapply(., "[",7,2, drop=TRUE)

names(ue_rate_data) <- ue_rate_names

ue_rate_data$Alabama[dim(ue_rate_data$Alabama)[1],]

ue_rate_data <- ue_rate_data %>%
  map_df(bind_rows, .id = "STATE")

colnames(ue_rate_data)

sapply(ue_rate_data, class)

ue_rate_data <- ue_rate_data %>%
  mutate(Year = as.numeric(Year)) %>%
  dplyr::select(STATE, Year, Annual) %>%
  rename("YEAR"=Year,
         "VALUE"=Annual) %>%
  mutate(VARIABLE="Unemployment_rate")
```

### Poverty rate

Extracted from Table 21 from [US Census Bureau](https://www.census.gov/data/tables/time-series/demo/income-poverty/historical-poverty-people.html)

**persistent warning from unknown origin** https://community.rstudio.com/t/persistent-unknown-or-uninitialised-column-warnings/64879

solution to above is alledgedly: "In any case the suggested approach is to initialize the column"

```{r}
poverty_rate_data <- read_xls("Data/Poverty/hstpov21.xls", skip=2)

head(poverty_rate_data)

colnames(poverty_rate_data) <- c("STATE",
                                 "Total",
                                 "Number",
                                 "Number_se",
                                 "Percent",
                                 "Percent_se")

tail(poverty_rate_data)

notes <- 4

poverty_rate_data <- poverty_rate_data[-((dim(poverty_rate_data)[1]-notes+1):dim(poverty_rate_data)[1]),]

states_eq <- 51

extra_col <- 2

rep_rows <- states_eq + extra_col

groups <- (dim(poverty_rate_data)[1])/(rep_rows)

paste(groups - (2018-1980 + 1), "extra groups.")

poverty_rate_data$year_group <- rep(1:groups, each=rep_rows) 

poverty_rate_data <- poverty_rate_data %>%
  group_by(year_group) %>%
  group_split()

head(poverty_rate_data[[1]])

poverty_rate_data <- poverty_rate_data %>%
  map(~mutate(.,
              row_id = row_number())) %>%
  map(~filter(.,row_id != 2)) %>%
  map(~dplyr::select(.,-row_id))

poverty_rate_data_names <- poverty_rate_data %>%
  sapply(., "[",1,1, drop=TRUE) %>%
  str_replace_all(.,"[:space:]","_")

names(poverty_rate_data) <- poverty_rate_data_names

# Recall 2 extra groups. 
# footnotes available at https://www.census.gov/topics/income-poverty/poverty/guidance/poverty-footnotes/cps-historic-footnotes.html

poverty_rate_data$`2017_(21)` <- NULL

poverty_rate_data$`2013_(19)` <- NULL

poverty_rate_data_names <- poverty_rate_data %>%
  sapply(., "[",1,1, drop=TRUE) %>%
  str_sub(., start = 1, end=4)

names(poverty_rate_data) <- poverty_rate_data_names

poverty_rate_data <- poverty_rate_data %>%
  map_df(bind_rows, .id = "YEAR") %>%
  dplyr::select(-year_group)

poverty_rate_data <- poverty_rate_data %>%
    mutate(n_na = rowSums(is.na(.))) 

# This shows that there is systematic missing values stemmingly *solely* from the rows without poverty data and only a label designating the year
poverty_rate_data %>% 
  group_by(n_na) %>%
  tally()

sapply(poverty_rate_data, class)

poverty_rate_data <- poverty_rate_data %>%
  drop_na() %>%
  dplyr::select(-Number,
                -Number_se,
                -Percent_se,
                -n_na,
                -Total) %>%
  rename("VALUE"=Percent) %>%
  mutate(VARIABLE = "Poverty_rate",
         YEAR = as.numeric(YEAR),
         VALUE = as.numeric(VALUE))

colnames(poverty_rate_data)
```

### Violent crime

https://www.ucrdatatool.gov/Search/Crime/State/StatebyState.cfm

```{r}
crime_data <- read_lines("Data/Crime/CrimeStatebyState.csv", skip = 2, skip_empty_rows = TRUE)

length(crime_data)

crime_data <- crime_data[-(2143:length(crime_data))]

x <- 2014-1977+1

rep_cycle <- 2 + 2 + x

rep_cycle_cut <- 2 + x

delete_rows <- c(seq(2,length(crime_data),rep_cycle),
                 seq(3,length(crime_data),rep_cycle))

crime_data <- crime_data[-delete_rows]

crime_data <- data.frame(cbind(crime_data, rep(1:(length(crime_data)/rep_cycle_cut),each=rep_cycle_cut)))

colnames(crime_data) <- c("String","STATE_GROUP")

crime_data <- crime_data %>%
  group_by(STATE_GROUP) %>%
  group_split()

columns_crime_data <- 8

crime_data <- crime_data %>%
  map(~mutate(.,
               State = case_when(str_detect(String, "Estimated crime in ") ~ substring(String, nchar("Estimated crime in ")+1)),
              row_id = row_number())) %>%
  map(~fill(., State)) %>%
  map(~filter(.,row_id > 2)) %>%
  map(~mutate(.,
              String = paste0(String, ",", State))) %>%
  map(~dplyr::select(.,String)) %>%
  map(~str_split_fixed(.$String,",",columns_crime_data + 1)) %>%
  map(~data.frame(.)) %>%
  map(~rename(.,"YEAR"=X1,
              "Extra_col1"=X2,
              "VC"=X3,
              "Extra_col2"=X4,
              "Extra_col3"=X5,
              "Extra_col4"=X6,
              "Extra_col5"=X7,
              "Extra_col6"=X8,
              "STATE"=X9)) %>%
  map(~dplyr::select(.,-contains("Extra_col"))) %>%
  map(~.x %>% mutate_all(~trimws(.,which = "both"))) %>%
  map_df(bind_rows)

sapply(crime_data, class)

crime_data <- crime_data %>%
  mutate(VARIABLE = "Viol_crime_count") %>%
  rename("VALUE" = VC) %>%
  as.tibble() %>%
  mutate(YEAR = as.numeric(YEAR),
         VALUE = as.numeric(VALUE))
```

### RTC laws

Extracted from table in [Donohue paper](https://www.nber.org/papers/w23510.pdf)

```{r}
syn_control_paper <- pdf_text("w23510.pdf")

syn_control_paper_p_62 <- syn_control_paper[[62]]

test <- syn_control_paper_p_62 %>%
    strsplit("\n") %>%
    unlist() %>%
    as.data.frame() %>%
    slice(-(1:2))

apply(test, 1, nchar)

test[53,] #physcial page 60

test <- test %>%
    slice(-53)

apply(test, 1, str_count, "\\s{5,}")
apply(test, 1, str_count, "\\s{10,}")
apply(test, 1, str_count, "\\s{20,}")
apply(test, 1, str_count, "\\s{40,}")

head(cbind(test, apply(test, 1, str_count, "\\s{40,}")))

test <- test %>%
    apply(1,str_replace_all, "\\s{40,}", "|N/A|") %>%
    str_replace_all("\\s{2,15}", "|") %>%
    as.data.frame()

test <- sapply(test$., str_split, "\\|{1,}")

sapply(test, nchar)

test <- lapply(test, function(x) x[nchar(x) > 0]) 

test <- as.data.frame(do.call(rbind, test))

rownames(test)

rownames(test) <- c()

colnames(test) <- c("STATE",
                    "E_Date_RTC",
                    "Frac_Yr_Eff_Yr_Pass",
                    "RTC_Date_SA")
sapply(test, class)

test <- test %>%
  dplyr::select(STATE, RTC_Date_SA) %>%
  rename("RTC_LAW_YEAR"=RTC_Date_SA) %>%
  mutate(RTC_LAW_YEAR = as.numeric(RTC_LAW_YEAR)) %>%
  mutate(RTC_LAW_YEAR = case_when(RTC_LAW_YEAR == 0 ~ Inf,
                              TRUE ~ RTC_LAW_YEAR))

sapply(test, class)
```

## Checkpoint

```{r}
colnames(dem_DONOHUE)
colnames(dem_LOTT)
colnames(ue_rate_data)
colnames(poverty_rate_data)
colnames(crime_data)

head(dem_DONOHUE)
head(dem_LOTT)
head(ue_rate_data)
head(poverty_rate_data)
head(crime_data)
```

## Join

### Donohue, et al.

```{r}
DONOHUE_DF <- bind_rows(dem_DONOHUE,
                        ue_rate_data,
                        poverty_rate_data,
                        crime_data,
                        population_data,
                        ps_data) %>%
  pivot_wider(names_from = "VARIABLE",
              values_from = "VALUE") %>%
  left_join(test , by = c("STATE")) %>%
  mutate(RTC_LAW = case_when(YEAR >= RTC_LAW_YEAR ~ TRUE,
                              TRUE ~ FALSE))

DONOHUE_DF %>%
  group_by(YEAR) %>%
  tally() %>%
  filter(n != 51) %>%
  print(n=dim(.)[1])

summary(as.factor(DONOHUE_DF$STATE))

max(DONOHUE_DF$YEAR) - min(DONOHUE_DF$YEAR) + 1

DONOHUE_DF <- DONOHUE_DF %>%
  mutate(STATE = fct_collapse(STATE, "District of Columbia"=c("District of Columbia","D.C.")))

summary(as.factor(DONOHUE_DF$STATE))
  
length(levels(DONOHUE_DF$STATE))

DONOHUE_DF <- DONOHUE_DF %>%
  group_by(STATE, YEAR) %>%
  summarise_all(~na.omit(unique(.))) %>%
  ungroup() # This identifies unique observations, coalesces rows according to the grouping variable(s), and gets rid of of units that have incomplete data. This gives returns a dataframe with the most complete information.

summary(as.factor(DONOHUE_DF$STATE)) 

baseline_year <- min(DONOHUE_DF$YEAR)
censoring_year <- max(DONOHUE_DF$YEAR)

# Need to fix this to ensure severe bias is not introduced by prevalent "cases"

DONOHUE_DF <- DONOHUE_DF %>%
  mutate(TIME_0 = baseline_year,
         TIME_INF = censoring_year) %>%
  filter(RTC_LAW_YEAR > TIME_0)

DONOHUE_DF <- DONOHUE_DF %>%
  mutate(Viol_crime_rate_1k = (Viol_crime_count*1000)/Population,
         Viol_crime_rate_1k_log = log(Viol_crime_rate_1k),
         Population_log = log(Population))

summary(droplevels(as.factor(DONOHUE_DF$STATE)))

length(summary(droplevels(as.factor(DONOHUE_DF$STATE))))
```

### Lott and Mustard

```{r}
LOTT_DF <- bind_rows(dem_LOTT,
                     ue_rate_data,
                     poverty_rate_data,
                     crime_data,
                     population_data,
                     ps_data) %>%
  pivot_wider(names_from = "VARIABLE",
              values_from = "VALUE") %>%
  left_join(test , by = c("STATE")) %>%
  mutate(RTC_LAW = case_when(YEAR >= RTC_LAW_YEAR ~ TRUE,
                              TRUE ~ FALSE))

LOTT_DF %>%
  group_by(YEAR) %>%
  tally() %>%
  filter(n != 51) %>%
  print(n=dim(.)[1])

summary(as.factor(LOTT_DF$STATE))

max(LOTT_DF$YEAR) - min(LOTT_DF$YEAR) + 1

LOTT_DF <- LOTT_DF %>%
  mutate(STATE = fct_collapse(STATE, "District of Columbia"=c("District of Columbia","D.C.")))

summary(as.factor(LOTT_DF$STATE))
  
length(levels(LOTT_DF$STATE))

LOTT_DF <- LOTT_DF %>%
  group_by(STATE, YEAR) %>%
  summarise_all(~na.omit(unique(.))) %>%
  ungroup() # This identifies unique observations, coalesces rows according to the grouping variable(s), and gets rid of of units that have incomplete data. This gives returns a dataframe with the most complete information.

summary(as.factor(LOTT_DF$STATE)) 

baseline_year <- min(LOTT_DF$YEAR)
censoring_year <- max(LOTT_DF$YEAR)

# Need to fix this to ensure severe bias is not introduced by prevalent "cases"

LOTT_DF <- LOTT_DF %>%
  mutate(TIME_0 = baseline_year,
         TIME_INF = censoring_year) %>%
  filter(RTC_LAW_YEAR > TIME_0)

LOTT_DF <- LOTT_DF %>%
  mutate(Viol_crime_rate_1k = (Viol_crime_count*1000)/Population,
         Viol_crime_rate_1k_log = log(Viol_crime_rate_1k),
         Population_log = log(Population))

summary(droplevels(as.factor(LOTT_DF$STATE)))

length(summary(droplevels(as.factor(LOTT_DF$STATE))))
```

# Data analysis

## Donohue, et al.

```{r}
sapply(DONOHUE_DF, class)

DONOHUE_DF %>%
  ggplot(aes(x = YEAR, y = (Viol_crime_count*100000)/Population)) +
  geom_line(aes(group=STATE), alpha = 0.1, show.legend = FALSE) + 
  geom_smooth() + 
  theme_minimal()

DONOHUE_DF %>%
  ggplot(aes(x = YEAR, y = (Viol_crime_count*100000)/Population)) +
  geom_smooth() + 
  theme_minimal()
```

Some code taken from http://karthur.org/2019/implementing-fixed-effects-panel-models-in-r.html

```{r}
d_panel <- pdata.frame(DONOHUE_DF, index=c("STATE", "YEAR"))

DONOHUE_OUTPUT <- plm(Viol_crime_rate_1k_log ~
                        RTC_LAW +
                        White_Male_15_to_19_years +
                        White_Male_20_to_39_years +
                        Black_Male_15_to_19_years +
                        Black_Male_20_to_39_years +
                        Other_Male_15_to_19_years +
                        Other_Male_20_to_39_years +
                        Unemployment_rate +
                        Poverty_rate + 
                        Population_log + 
                        police_per_100k_lag,
                      effect = "twoways",
                      model = "within",
                      data=d_panel)

summary(DONOHUE_OUTPUT)

design.matrix <- as.data.frame(model.matrix(DONOHUE_OUTPUT))

design.matrix$Viol_crime_rate_1k_log <- plm::Within(
  d_panel$Viol_crime_rate_1k_log)

lm_DONOHUE <- lm(Viol_crime_rate_1k_log ~
                        RTC_LAWTRUE + # logical class changes variable name after inital model
                        White_Male_15_to_19_years +
                        White_Male_20_to_39_years +
                        Black_Male_15_to_19_years +
                        Black_Male_20_to_39_years +
                        Other_Male_15_to_19_years +
                        Other_Male_20_to_39_years +
                        Unemployment_rate +
                        Poverty_rate + 
                        Population_log +
               police_per_100k_lag,
             data = design.matrix)


vif(lm_DONOHUE)
```

## Lott and Mustard

Some code taken from http://karthur.org/2019/implementing-fixed-effects-panel-models-in-r.html

```{r}
LOTT_variables <- LOTT_DF %>%
  dplyr::select(RTC_LAW,
                contains(c("White","Black","Other")),
                Unemployment_rate,
                Poverty_rate,
                Population_log,
                police_per_100k_lag) %>%
  colnames()

LOTT_fmla <- as.formula(paste("Viol_crime_rate_1k_log ~",
                              paste(LOTT_variables, collapse = " + ")
                              )
                        )

d_panel <- pdata.frame(LOTT_DF, index=c("STATE", "YEAR"))

LOTT_OUTPUT <- plm(LOTT_fmla,
                      model = "within",
                   effect = "twoways",
                      data=d_panel)

summary(LOTT_OUTPUT)

design.matrix <- as.data.frame(model.matrix(LOTT_OUTPUT))

design.matrix$Viol_crime_rate_1k_log <- plm::Within(
  d_panel$Viol_crime_rate_1k_log)

LOTT_variables_ols <- LOTT_DF %>%
  dplyr::select(RTC_LAW,
                contains(c("White","Black","Other")),
                Unemployment_rate,
                Poverty_rate,
                Population_log,
                police_per_100k_lag) %>%
  colnames() %>%
  str_replace("RTC_LAW", "RTC_LAWTRUE") # logical class changes variable name after inital model

LOTT_fmla_ols <- as.formula(paste("Viol_crime_rate_1k_log ~",
                              paste(LOTT_variables_ols, collapse = " + ")
                              )
                        )

lm_LOTT <- lm(LOTT_fmla_ols,
             data = design.matrix)

vif(lm_LOTT)
```

# Possible homework question

Below is another directed acyclic graph representing what we believe the true relationship between variables is. This directed acyclic graph is different than the one first presented. 

Assume this is the correct directed acyclic graph: what did we do in our analysis that would limit the effect of simultaneity between police staffing and violent crime on our effect estimates? 

Let's pretend that summertime humidity is associated with the adoption of a right-to-carry law but not with violent crime. Should we include humidity in our model? 

Would we include beer in our adjustment set if violent crime instead led to an increase in beer consumption? Why not? What type of variable would beer consumption be? 

```{r}
coords2 <- tibble::tribble(
  ~name, ~x, ~y,
  "VC", 2, 0,
  "RTC", 1, 0,
  "Dem", 1.5, 2,
  "Beer", 1.5, 1,
  "UE", 2, -2,
  "Poverty", 1.5, -1,
  "PS", 2, 2,
  "Humidity", 1, -2
)

DAG2 <- dagify(VC ~ RTC + Dem + Beer + UE + Poverty,
               VC ~~ PS,
               RTC ~ Dem, 
               RTC ~ Humidity, 
               Beer ~ Dem,
               Poverty ~ UE,
       labels = c("VC" = "Violent\nCrime", 
                  "RTC" = "RTC\nLaw",
                  "Beer" = "Beer",
                  "Dem" = "Demographics",
                  "UE" = "Unemployment",
                  "Poverty" = "Poverty",
                  "PS" = "Police Staffing",
                  "Humidity" = "Summertime Humidity"),
       coords = coords2)


ggdag(DAG2, text = FALSE,use_labels = "label") +
  theme_void() + 
  labs(title = "DAG")
```


helpful_link

https://rpubs.com/rslbliss/fixed_effects

http://karthur.org/2019/implementing-fixed-effects-panel-models-in-r.html

https://stats.stackexchange.com/questions/99236/effects-in-panel-models-individual-time-or-twoways

# Code Garage

### Beer 

The following data was downloaded from the [National Institutes of Health](https://pubs.niaaa.nih.gov/publications/surveillance115/pcyr1970-2018.txt)

```{r, eval=FALSE}
beer_df <- read_table2("Data/Beer/pcyr1970-2018.txt", col_names = FALSE, skip = 131)
colnames(beer_df)

head(beer_df)

columns_beer <- c("YEAR",
                  "STATEFP",
                  "Beverage",
                  "Gal_bev",
                  "Gal_eth",
                  "Pop_least_14",
                  "Gal_eth_cap_least_14",
                  "Cap_decile_least_14",
                  "Pop_least_21",
                  "Gal_eth_cap_least_21",
                  "Cap_decile_least_21",
                  "Data_source",
                  "TV_ABV",
                  "Gal_eth_TV_ABV")

colnames(beer_df) <- columns_beer

class(beer_df$Beverage)

beer_df <- beer_df %>%
    mutate(STATEFP = str_pad(STATEFP, 2, pad = "0"),
           Beverage = as.character(Beverage)) %>%
    mutate(Beverage = recode_factor(Beverage,
                                    `1`="Spirits",
                                    `2`="Wine",
                                    `3` = "Beer",
                                    `4` = "All beverages")) %>%
    filter(Beverage == "Beer",
           !STATEFP %in% c("91","92","93","94","99")) %>%
    dplyr::select(YEAR, STATEFP, Gal_eth_cap_least_21) %>%
    rename("Gal_beer_cap"=Gal_eth_cap_least_21) %>%
    mutate(Gal_beer_cap = Gal_beer_cap/10000) %>% # /10000 for correct value (see df)
    left_join(STATE_FIPS, by = "STATEFP")

beer_df <- beer_df %>%
  dplyr::select(-STATEFP) %>%
  pivot_longer(cols="Gal_beer_cap",
               names_to = "VARIABLE",
               values_to = "VALUE")
```