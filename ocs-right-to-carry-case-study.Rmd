---
title: "Open Case Studies: Examination of Multicollinearity Influence on Inference Using Right-to-Carry Gun Law and Violent Crime Data"
author: "Michael Ontiveros, Carrie Wright, PhD."
css: style.css
output:
  html_document:
    self_contained: yes
    code_download: yes
    highlight: tango
    number_sections: no
    theme: cosmo
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
  word_document:
    toc: yes
---

<style>
#TOC {
  background: url("https://opencasestudies.github.io/img/logo.jpg");
  background-size: contain;
  padding-top: 240px !important;
  background-repeat: no-repeat;
}
</style>


---


```{r setup, include=FALSE}
knitr::opts_chunk$set(include = TRUE, comment = NA, echo = TRUE,
                      message = FALSE, warning = FALSE, cache = FALSE, fig.width=10, fig.height=7,
                      fig.align = "center", out.width = '90%')
library(here)
library(knitr)
```

#### {.outline }
```{r, echo = FALSE, out.width = "800 px"}
knitr::include_graphics(here::here("img", "mainplot.png"))
```

####

## {.disclaimer_block}

**Disclaimer**: The purpose of the [Open Case Studies](https://opencasestudies.github.io){target="_blank"} project is **to demonstrate the use of various data science methods, tools, and software in the context of messy, real-world data**. A given case study does not cover all aspects of the research process, is not claiming to be the most appropriate way to analyze a given data set, and should not be used in the context of making policy decisions without external consultation from scientific experts. 

## {.liscence_block}

This work is licensed under the Creative Commons Attribution-NonCommercial 3.0 [(CC BY-NC 3.0)](https://creativecommons.org/licenses/by-nc/3.0/us/){target="_blank"}  United States License.

# **Motivation**
*** 

This case study will introduce the topic of multicolinearity. We will do so by showcasing a real world example where multicolinearity in part resulted in historically contriversial and conflicting findings about the influence of the adoption of right-to-carry (RTC) concealed handgun laws on violent crime rates in the United States. 

We will focus on two articles:

1) The first analysis by [Lott and Mustard](https://chicagounbound.uchicago.edu/cgi/viewcontent.cgi?article=1150&context=law_and_economics){target="_blank"} published in 1996 suggests that RTC laws reduce violent crime. Lott authored a book extending these findings in 1998 called [***More Guns, Less Crime***](https://en.wikipedia.org/wiki/More_Guns,_Less_Crime){target="_blank"}.

```{r, echo=FALSE, out.height = '100%', out.width = '100%', fig.align='center'}
knitr::include_graphics(here("img", "Lott.png"))
```

2) The second analysis is a recent article by [Donohue, et al.](https://www.nber.org/papers/w23510.pdf){target="_blank"} published in 2017 that suggests that RTC laws increase violent crime. Donohue has also published previous articles with titles such as [***"Shooting down the "More Guns, Less Crime" Hypothesis***](https://www.jstor.org/stable/1229603?seq=1){target="_blank"} 

```{r, echo=FALSE, out.height = '100%', out.width = '100%', fig.align='center'}
knitr::include_graphics(here("img", "Donohue.png"))
```

This has been a controversial topic as many other articles also had conflicting results. See [here](https://en.wikipedia.org/wiki/More_Guns,_Less_Crime){target="_blank"} for a list of studies.

The [Donohue, et al.](https://www.nber.org/papers/w23510.pdf){target="_blank"} article discusses how there are many other important methodolical aspects besides multicolinearity that could account for the historically conflicting results in these previous papers.

In fact, nearly every aspect of the data analysis process was different between the [Donohue, et al.](https://www.nber.org/papers/w23510.pdf){target="_blank"} analysis and the [Lott and Mustard](https://chicagounbound.uchicago.edu/cgi/viewcontent.cgi?article=1150&context=law_and_economics){target="_blank"} analysis.

```{r, echo=FALSE, out.height = '75%', out.width = '75%', fig.align='center'}
knitr::include_graphics(here("img", "Educational_Graphic1.jpg"))
```

However, we will focus particularly on multicolinearity and we will explore how it can influence linear regression analyses and result in different conclusions. 

This analysis will demonstrate how methodological details can be critically influential for our overall conclusions and can result in important policy related consequences. This [article]((https://www.nber.org/papers/w23510.pdf){target="_blank"}) will provide a basis for the motivation. 

#### {.reference_block}

John J. Donohue et al., Right‐to‐Carry Laws and Violent Crime: A Comprehensive Assessment Using Panel Data and a State‐Level Synthetic Control Analysis. *Journal of Empirical Legal Studies*, 16,2 (2019).

David B. Mustard & John Lott. Crime, Deterrence, and Right-to-Carry Concealed Handguns. *Coase-Sandor Institute for Law & Economics* Working Paper No. 41, (1996).

####


Here you can see the differences in the data used in the featured RTC articles:


```{r, echo=FALSE, out.height = '100%', out.width = '100%', fig.align='center'}
knitr::include_graphics(here("img",'Donohue_Table2.png'))
```


We will perform analyses similar to those in these articles, however **we will not try to recreate them**, instead we will simplify our analysis to allow us to focus on multicolinearity.


Therefore we will use a subset of the listed explanatory variables and they will be consistent for both analyses that we will perform, with the exception that one analysis will have 6 demographic variables like the analysis in the [Donohue, et al.](https://www.nber.org/papers/w23510.pdf){target="_blank"} article and the other will have 36 demogrpahic variables like the analysis in the [Lott and Mustard](https://chicagounbound.uchicago.edu/cgi/viewcontent.cgi?article=1150&context=law_and_economics){target="_blank"} article.


# **Main Question**
*** 

#### {.main_question_block}
<b><u> Our main question: </u></b>

1) How does the inclusion of different numbers of age groups influence the results of an analysis of right to carry laws and violence rates?

####


# **Learning Objectives** 
*** 

<u>**Statistical Learning Objectives:**</u> 

In this case study, students will learn:  
1) what multicolinearity is and how it can influence linear regression coefficients  
2) how to look for the presence of multicolinarity  
3) the difference between multicolinearity and correlation  

<u>**Data science Learning Objectives:**</u>

1) joining data from multiple sources (dplyr)  
2) reshaping data into different formats (tidyr)  
2) visualizations (ggplot2)  


We will especially focus on using packages and functions from the [`Tidyverse`](https://www.tidyverse.org/){target="_blank"}, such as `dplyr` and `ggplot2`. The tidyverse is a library of packages created by RStudio. While some students may be familiar with previous R programming packages, these packages make data science in R especially efficient.


```{r, out.width = "20%", echo = FALSE, fig.align ="center"}
include_graphics("https://tidyverse.tidyverse.org/logo.png")
```

# **Context**
***

So what exactly is a **right-to-carry law**?

It is a law thatspecifies if and how citizens are allowed to have a firearm on their person or nearby (for example in the citizen's car) in public. 

The [Second Amendment](https://en.wikipedia.org/wiki/Second_Amendment_to_the_United_States_Constitution){target="_blank"} to the United States Constitution guarantees the right to "keep and bear arms". The amendment was ratified in 1791 as part of the [Bill of Rights](https://en.wikipedia.org/wiki/United_States_Bill_of_Rights){target="_blank"}.

```{r, echo=FALSE, out.height = '50%', out.width = '50%', fig.align='center'}
knitr::include_graphics("https://upload.wikimedia.org/wikipedia/commons/7/79/Bill_of_Rights_Pg1of1_AC.jpg")
```

However, there are no federal laws about carrying firearms in public. 

These laws are created and enforced at the state level. Sates vary greatly in their laws about the right to carry firearms. Some require extensive effort to obtain a permit to legally carry a firearm, while other states require very minimal effort to legally carry a firearm.


According to Wikipedia about the history of right-to-carry policies in the United States:

> Public perception on concealed carry vs open carry has largely flipped. In the early days of the United States, open carrying of firearms, long guns and revolvers was a common and well-accepted practice. Seeing guns carried openly was not considered to be any cause for alarm. Therefore, anyone who would carry a firearm but attempt to conceal it was considered to have something to hide, and presumed to be a criminal. For this reason, concealed carry was denounced as a detestable practice in the early days of the United States.

> Concealed weapons bans were passed in Kentucky and Louisiana in 1813. (In those days open carry of weapons for self-defense was considered acceptable; concealed carry was denounced as the practice of criminals.) By 1859, Indiana, Tennessee, Virginia, Alabama, and Ohio had followed suit. By the end of the nineteenth century, similar laws were passed in places such as Texas, Florida, and Oklahoma, which protected some gun rights in their state constitutions. Before the mid 1900s, most U.S. states had passed concealed carry laws rather than banning weapons completely. Until the late 1990s, many Southern states were either "No-Issue" or "Restrictive May-Issue". Since then, these states have largely enacted "Shall-Issue" licensing laws, with numerous states legalizing "Unrestricted concealed carry".

See [here](https://en.wikipedia.org/wiki/History_of_concealed_carry_in_the_U.S.){target="_blank"} for more information.

Here are the general categories of Right to Carry Laws:

```{r, echo=FALSE, out.height = '100%', out.width = '100%', fig.align='center'}
knitr::include_graphics(here("img", "RTC.png"))
```
[source](https://www.nraila.org/gun-laws/){target="_blank"}


```{r, echo=FALSE, out.height = '100%', out.width = '100%', fig.align='center'}
knitr::include_graphics(here("img", "RTC_map.png"))
```

[source](https://www.nraila.org/gun-laws/){target="_blank"}

You can see that none of the fifty states have no-issue laws currently, meaning that all states allow the right to carry firearms at least in some way, however the level of restrictions is dramatically different from one state to another.

Here you can see how these laws have changed over time around the country:
```{r, echo=FALSE, out.height = '100%', out.width = '100%', fig.align='center'}
knitr::include_graphics("https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Right_to_Carry%2C_timeline.gif/620px-Right_to_Carry%2C_timeline.gif")
```

There is variation from state to state even within the same general category:

For example here are the [current carry laws in Idaho](https://www.nraila.org/gun-laws/state-gun-laws/idaho/) which is considered an "Unrestricted - no permit required" state:

>Idaho permits the open carrying of firearms.

>Idaho law permits both residents and non-residents who are at least 18 years old to carry concealed weapons, without a carry license, outside the limits of or confines of any city, provided the person is not otherwise disqualified from being issued a license to carry.

>A person may also carry concealed weapons on or about his or her person, without a license, in the person’s own place of abode or fixed place of business, on property in which the person has any ownership or leasehold interest, or on private property where the person has permission to carry from any person who has an ownership or leasehold interest in that property. 

>State law also allows any resident of Idaho or a current member of the armed forces of the United States to carry a concealed handgun without a license to carry, provided the person is over 18 years old and not disqualified from being issued a license to carry concealed weapons under state law. An amendment to state law that takes effect on July 1, 2020 changes the reference in the above law from “a resident of Idaho” to “any citizen of the United States.”  


And here are the [current carry laws in Arizona](https://www.nraila.org/gun-laws/state-gun-laws/arizona/) which is also considered an "Unrestricted- - no permit required" state:

> Arizona respects the right of law abiding citizens to openly carry a handgun.

> Any person 21 years of age or older, who is not prohibited possessor, may carry a weapon openly or concealed without the need for a license. Any person carrying without a license must acknowledge and comply with the demands of a law enforcement officer when asked if he/she is carrying a concealed deadly weapon, if the officer has initiated an "investigation" such as a traffic stop.

Notice that citizens in Idaho only need to be 18 to carry a firearm, whereas they must be 21 in Arizona. 


In contrast here is an example of [current carry laws in Maryland](https://www.nraila.org/gun-laws/state-gun-laws/maryland/) which is considered a "Rights Restricted-Very Limited Issue" state:

>Carrying and Transportation in Vehicles
It is unlawful for any person without a permit to wear or carry a handgun, openly or concealed, upon or about his person.  It is also unlawful for any person to knowingly transport a handgun in any vehicle traveling on public roads, highways, waterways or airways, or upon roads or parking lots generally used by the public. This does not apply to any person wearing, carrying or transporting a handgun within the confines of real estate owned or leased by him, or on which he resides, or within the confines of a business establishment owned or leased by him.

>Permit To Carry
Application for a permit to carry a handgun is made to the Secretary of State Police.  In addition to the printed application form, the applicant should submit a notarized letter stating the reasons why he is applying for a permit.


avocado....Right to carry and covid masks?

# **Limitations**
*** 
There are some important considerations regarding this data analysis to keep in mind: 

1) We do not use all of the data used by either the  [Lott and Mustard](https://chicagounbound.uchicago.edu/cgi/viewcontent.cgi?article=1150&context=law_and_economics){target="_blank"} or [Donohue, et al.](https://www.nber.org/papers/w23510.pdf){target="_blank"} analyses, nor do we perform the same analysis of each article. We instead perform a much simpler analysis with less variables for the purposes of illustration of the concept of multicollinearity and its influence on regression coefficients, not to reproduce either analysis.

2) Because our analysis is an oversimplification, our analysis should not be used for determining policy changes, instead we suggest that users consult with a specialist.


We would also like to note that...AVOCADO
It is important that we do not treat race as an objective measure. Despite this, it can be used to advance scientific inquiry. For more information on this topic, we have included a link to a [paper on the use of race as a measure in epidemiology](https://academic.oup.com/epirev/article/22/2/187/456942). 


We will begin by loading the packages that we will need:

```{r}
library(here) 
library(car) # vif function
library(plm) # fixed effect model, linear regression
library(broom) # tidy output
library(tidyverse) # general wrangling functions
library(pdftools) # read data from pdf 
library(readxl) # importing excel sheets
library(cowplot) # to produce plot of plots 
library(GGally)
library(ggrepel)
library(scales)
library(latex2exp)
library(viridis)
library(ggcorrplot)
library(rsample)

set.seed(999)
```


 Package   | Use                                                                         
---------- |-------------
[here](https://github.com/jennybc/here_here){target="_blank"}       | to easily load and save data
[readr](https://readr.tidyverse.org/){target="_blank"}      | to import the CSV file data
[car]  | to calculate vif values

The first time we use a function, we will use the `::` to indicate which package we are using. Unless we have overlapping function names, this is not necessary, but we will include it here to be informative about where the functions we will use come from.


# **What are the data?**
***

Below is a table from the [Donohue, et al.](https://www.nber.org/papers/w23510.pdf) paper that shows the data used in both analyses, where DAW stands for [Donohue, et al.](https://www.nber.org/papers/w23510.pdf){target="_blank"} and LM stands for [Lott and Mustard](https://chicagounbound.uchicago.edu/cgi/viewcontent.cgi?article=1150&context=law_and_economics){target="_blank"}.


```{r, echo=FALSE, out.height = '100%', out.width = '100%', fig.align='center'}
knitr::include_graphics(here("img", "Donohue_AppendixJ.png"))
```

We will be using a subset of these variables, which are highlighted in green:


```{r, echo=FALSE, out.height = '100%', out.width = '100%', fig.align='center'}
knitr::include_graphics(here("img", "ourdata.png"))
```


# **Data Import**
***

##State FIPS codes
Avocado why do we need State FIPS?

The following data was downloaded from the [US Census Bureau](https://www.census.gov/geographies/reference-files/2014/demo/popest/2014-geocodes-state.html).

To import the data we will use the `read_xls()` function of the `readxl` package. Since the first five lines of this excel is information about the source of the data and when it was released, we need to skip importing these lines using the `skip` argument so that the data has the same number of columns for each row. 

```{r}
knitr::include_graphics(here("img", "FIPS.png"))

```

```{r}
STATE_FIPS <- read_xls("docs/State_FIPS_codes/state-geocodes-v2014.xls", skip = 5)
```

## Demographic and Population data

To obtain information about age, sex, and race, and overall population we will use US Census Bureau data, just like both of the articles. The cesnus data is available for different time spans. Here are the links for the years used in our analysis. We will use data from 1977 to 2010.

Data   | Link                                                                        
---------- |-------------
**years 1977 to 1979**  | [link](https://www2.census.gov/programs-surveys/popest/tables/1900-1980/state/asrh/)  
**years 1980 to 1989**  | [link](https://www2.census.gov/programs-surveys/popest/tables/1980-1990/counties/asrh/) * county data was used for this decade
**years 1990 to 1999**  | [link](https://www2.census.gov/programs-surveys/popest/tables/1990-2000/state/asrh/)
**years 2000 to 2010**  | [link](https://www.census.gov/data/datasets/time-series/demo/popest/intercensal-2000-2010-state.html) <br> [technical documentation](https://www2.census.gov/programs-surveys/popest/technical-documentation/file-layouts/2000-2010/intercensal/state/st-est00int-alldata.pdf)

To import the data we will use the `read_csv()` function of the `readr` package for the csv files. In some decades, there are separate files for each year, we will read each of these together using the base `list.files()` function to get all of the names for each file and then the `map()` function of the `purrr` package to apply the `read_csv()` function on all of the file paths in the list created by `list.files()`. For years that are txt files we will use `read_table2()` also fo the `readr` package. The `read_table2()` function, unlike the `read_table()`,  allows for any number of whitespace characters between columns, and the lines can be of different lengths.

AVOCADO I am a bit confused about the last decade... it's only one file but it seems to need map...

```{r}

dem_77_79 <- read_csv("docs/Demographics/Decade_1970/pe-19.csv", skip = 5)

dem_80_89 <- list.files(recursive = TRUE,
                  path = "docs/Demographics/Decade_1980/",
                  pattern = "*.csv",
                  full.names = TRUE) %>% 
  map(~read_csv(., skip=5))

dem_90_99 <- list.files(recursive = TRUE,
                  path = "docs/Demographics/Decade_1990/",
                  pattern = "*.txt",
                  full.names = TRUE) %>% 
  map(~read_table2(., skip = 14))


dem_90_99 <- dem_90_99 %>%
  map_df(bind_rows)


dem_00_10_2 <- read_csv("docs/Demographics/Decade_2000/st-est00int-alldata.csv")

dem_00_10 <- list.files(recursive = TRUE,
                  path = "docs/Demographics/Decade_2000/",
                  pattern = "*.csv",
                   full.names = TRUE) %>% 
   map(~read_csv(.))


```

## Police staffing data
The following data was downloaded from the [Federal Bureau of Investigation](https://crime-data-explorer.fr.cloud.gov/downloads-and-docs). 


The `read_csv()` function of the `readr` package guesses what the class is for each variable, but sometimes it makes mistakes. It is good to specify the class for variables if you know them. We know that we want the variables about male and female counts to be numeric. We can specify that using the `col_types =` argument. See [here](https://readr.tidyverse.org/articles/readr.html) and [here](https://cran.r-project.org/web/packages/readr/vignettes/readr.html) for more information.

```{r}
ps_data <- read_csv("docs/Police_staffing/pe_1960_2018.csv")
ps_data <- read_csv("docs/Police_staffing/pe_1960_2018.csv",
                    col_types = cols(male_total_ct = "n",
                                     female_total_ct = "n"))

ps_data <- read_csv("docs/Police_staffing/pe_1960_2018.csv",
                   col_types =  cols(male_total_ct = col_double(),
                                   female_total_ct = col_double()))
                              
```



## Unemplyment data

The following data was downloaded from the [U.S. Bureau of Labor Statistics](https://data.bls.gov/cgi-bin/dsrv?la). 

There are excel files for each state.  As you can see, there are many rows to skip to make sure that there are the same number of columns for each row. We can also see that the state name is located in a couple of the first rows. 

```{r}
knitr::include_graphics(here("img", "Unemp.png"))
```

We can also see that here if we just try to read in the files directly.

```{r}

ue_rate_data <- list.files(recursive = TRUE,
                  path = "docs/Unemployment",
                  pattern = "*.xlsx",
                  full.names = TRUE) %>% 
  map(~read_xlsx(.))
      
head(ue_rate_data)[1]
```

So now we will skip the first 10 lines. And also create a names tibble that contains only the cell with the state information.

```{r}
 
 ue_rate_data <- list.files(recursive = TRUE,
                  path = "docs/Unemployment",
                  pattern = "*.xlsx",
                  full.names = TRUE) %>% 
  map(~read_xlsx(., skip = 10))
  
                 
# ue_rate_names <- list.files(recursive = TRUE,
#                   path = "docs/Unemployment",
#                   pattern = "*.xlsx",
#                   full.names = TRUE) %>%
#   map(~read_xlsx(.)) %>%
#   sapply(., "[",7,2, drop=TRUE)
```

To get the state name for each file, we will specifically import only a small range of cells and then grab the cell that has state information and the use the base `unlist()` function to unlist the list of lists that this creates.

```{r}
ue_rate_names <- list.files(recursive = TRUE,
                  path = "docs/Unemployment",
                  pattern = "*.xlsx",
                  full.names = TRUE) %>%
  map(~read_xlsx(., range = "B4:D6")) %>%
  map(., c(1,2)) %>%
  unlist()


ue_rate_data
ue_rate_names
```
## Poverty data
Extracted from Table 21 from [US Census Bureau Poverty Data ](https://www.census.gov/data/tables/time-series/demo/income-poverty/historical-poverty-people.html)

AVOCado strange issue

```{r}

#**persistent warning from unknown origin** https://community.rstudio.com/t/persistent-unknown-or-uninitialised-column-warnings/64879

#solution to above is alledgedly: "In any case the suggested approach is to initialize the column"


poverty_rate_data <- read_xls("docs/Poverty/hstpov21.xls", skip=2) #This may cause initialization issue, not easily reproducible (even after restarting R)
```

## Violent crime

Violent crime data was obtained from [here](https://www.ucrdatatool.gov/Search/Crime/State/StatebyState.cfm) This data is a bit trickier because of spaces and `/` in the column names, thus the `read_lines()` function of the `readr` package works better than the `read_csv()` function.


```{r}
knitr::include_graphics(here("img", "crime.png"))
```

```{r}
crime_data <- read_lines("docs/Crime/CrimeStatebyState.csv", skip = 2, skip_empty_rows = TRUE)

```


## Right-to-carry data

This data is extracted from table in [Donohue paper](https://www.nber.org/papers/w23510.pdf). We will use the function `pdf_text()`  of the `pdftools` package to import the pdf document.

```{r}

if(!file.exists(here("docs", "w23510.pdf"))){
  url <- "https://www.nber.org/papers/w23510.pdf"
  utils::download.file(url, here("docs", "w23510.pdf"))
}

DAWpaper <- pdf_text(here("docs", "w23510.pdf"))

```





# **Data Wrangling**
***
## State FIPS codes

```{r}

head(STATE_FIPS)

colnames(STATE_FIPS) <- c("Region",
                          "Division",
                          "STATEFP",
                          "STATE")

class(STATE_FIPS$STATEFP)

STATE_FIPS <- STATE_FIPS %>%
    filter(STATEFP!="00") %>%
    dplyr::select(STATEFP, STATE)
```

## Demographics

#### 1977-1979


```{r}
head(dem_77_79)

colnames(dem_77_79)

class(dem_77_79$`Year of Estimate`)

dem_77_79 <- dem_77_79 %>%
  mutate(RACE = case_when(str_detect(`Race/Sex Indicator`,"Black") ~ "Black",
                          str_detect(`Race/Sex Indicator`,"White") ~ "White",
                          TRUE ~ "Other"),
         SEX = case_when(str_detect(`Race/Sex Indicator`,"female") ~ "Female",
                         TRUE ~ "Male")) %>%
  dplyr::select(-`Race/Sex Indicator`,-`FIPS State Code`)

dem_77_79 <- dem_77_79 %>%
    rename("YEAR"=`Year of Estimate`,
           "STATE"=`State Name`) %>%
    filter(YEAR %in% 1977:1979)
    
dem_77_79 <- dem_77_79 %>%
  pivot_longer(cols=contains("years"),
               names_to = "AGE_GROUP",
               values_to = "SUB_POP")

colnames(dem_77_79)

pop_77_79 <- dem_77_79 %>%
  group_by(YEAR, STATE) %>%
  summarise("TOT_POP" = sum(SUB_POP), .groups = "drop") 

colnames(pop_77_79)

dem_77_79 <- dem_77_79 %>%
  left_join(pop_77_79, by = c("YEAR","STATE")) %>%
  mutate(PERC_SUB_POP = SUB_POP*100/TOT_POP) %>%
  dplyr::select(-SUB_POP, -TOT_POP)
```

#### 1980-1989




```{r}
dem_80_89 <- dem_80_89 %>%
  map_df(bind_rows)

sapply(dem_80_89, class)

dem_80_89 <- dem_80_89 %>%
  mutate(RACE = case_when(str_detect(`Race/Sex Indicator`,"Black") ~ "Black",
                          str_detect(`Race/Sex Indicator`,"White") ~ "White",
                          TRUE ~ "Other"),
         SEX = case_when(str_detect(`Race/Sex Indicator`,"female") ~ "Female",
                         TRUE ~ "Male")) %>%
  dplyr::select(-`Race/Sex Indicator`)

colnames(dem_80_89)

dem_80_89 <- dem_80_89 %>% 
    rename("YEAR"=`Year of Estimate`,
           "STATEFP_temp"=`FIPS State and County Codes`) %>%
    mutate(STATEFP = substr(STATEFP_temp, start = 1, stop = 2)) %>%
    left_join(STATE_FIPS, by = "STATEFP") %>%
  dplyr::select(-STATEFP)

dem_80_89 <- dem_80_89 %>%
  pivot_longer(cols=contains("years"),
               names_to = "AGE_GROUP",
               values_to = "SUB_POP_temp") %>%
  group_by(YEAR, STATE, AGE_GROUP, SEX, RACE) %>%
  summarise(SUB_POP = sum(SUB_POP_temp), .groups="drop")
  
colnames(dem_80_89)

pop_80_89 <- dem_80_89 %>%
  group_by(YEAR, STATE) %>%
  summarise("TOT_POP" = sum(SUB_POP), .groups = "drop") 

colnames(pop_80_89)

dem_80_89 <- dem_80_89 %>%
  left_join(pop_80_89, by = c("YEAR","STATE")) %>%
  mutate(PERC_SUB_POP = SUB_POP*100/TOT_POP) %>%
  dplyr::select(-SUB_POP, -TOT_POP)
```

#### 1990-1999


```{r}


colnames(dem_90_99)

head(dem_90_99)

colnames(dem_90_99) <- c("YEAR",
                         "STATEFP",
                         "Age",
                         "NH_W_M",
                         "NH_W_F",
                         "NH_B_M",
                         "NH_B_F",
                         "NH_AIAN_M",
                         "NH_AIAN_F",
                         "NH_API_M",
                         "NH_API_F",
                         "H_W_M",
                         "H_W_F",
                         "H_B_M",
                         "H_B_F",
                         "H_AIAN_M",
                         "H_AIAN_F",
                         "H_API_M",
                         "H_API_F")

dim(dem_90_99)

dem_90_99 <- dem_90_99 %>%
    mutate(W_M = NH_W_M + H_W_M,
           W_F = NH_W_F + H_W_F,
           B_M = NH_B_M + H_B_M,
           B_F = NH_B_F + H_B_F,
           AIAN_M = NH_AIAN_M + H_AIAN_M,
           AIAN_F = NH_AIAN_F + H_AIAN_F,
           API_M = NH_API_M + H_API_M,
           API_F = NH_API_F + H_API_F,
           n_na = rowSums(is.na(.))) %>%
  dplyr::select(-starts_with("NH_"), -starts_with("H_"))

dem_90_99 %>%
  group_by(n_na) %>%
  tally()

empty_rows_na <- dem_90_99 %>%
  group_by(n_na) %>%
  tally() %>%
  filter(n_na != 0) %>%
  pull(n_na)

dem_90_99 <- dem_90_99 %>%
  filter(n_na != empty_rows_na) %>%
  dplyr::select(-n_na)

sapply(dem_90_99, class)

summary(as.factor(dem_80_89$AGE_GROUP))

dem_90_99 <- dem_90_99 %>%
  mutate(AGE_GROUP = cut(Age,
                         breaks = seq(0,90, by=5),
                         right = FALSE,
                         labels = c("Under 5 years",
                                    "5 to 9 years",
                                    "10 to 14 years",
                                    "15 to 19 years",
                                    "20 to 24 years",
                                    "25 to 29 years",
                                    "30 to 34 years",
                                    "35 to 39 years",
                                    "40 to 44 years",
                                    "45 to 49 years",
                                    "50 to 54 years",
                                    "55 to 59 years",
                                    "60 to 64 years",
                                    "65 to 69 years",
                                    "70 to 74 years",
                                    "75 to 79 years",
                                    "80 to 84 years",
                                    "85 years and over")
                         )) %>%
  dplyr::select(-Age) %>%
  mutate(AGE_GROUP = as.character(AGE_GROUP))

sapply(dem_90_99, class)

dem_90_99 <- dem_90_99 %>%
  group_by(YEAR, STATEFP, AGE_GROUP) %>%
  summarise_at(vars(starts_with("W_"),
                    starts_with("B_"),
                    starts_with("AIAN_"),
                    starts_with("API_")), sum) %>%
  ungroup() %>%
  pivot_longer(cols = c(starts_with("W_"),
                    starts_with("B_"),
                    starts_with("AIAN_"),
                    starts_with("API_")),
               names_to = "RACE",
               values_to = "SUB_POP")

dem_90_99 <- dem_90_99 %>%
  mutate(SEX = case_when(str_detect(RACE, "_M") ~ "Male",
                         TRUE ~ "Female"),
         RACE = case_when(str_detect(RACE, "W_") ~ "White",
                          str_detect(RACE, "B_") ~ "Black",
                          TRUE ~ "Other")) %>%
  left_join(STATE_FIPS, by = "STATEFP") %>%
  dplyr::select(-STATEFP)

pop_90_99 <- dem_90_99 %>%
  group_by(YEAR, STATE) %>%
  summarise(TOT_POP = sum(SUB_POP), .groups = "drop")

dem_90_99 <- dem_90_99 %>%
  left_join(pop_90_99, by=c("YEAR", "STATE")) %>%
  mutate(PERC_SUB_POP = SUB_POP*100/TOT_POP) %>%
  dplyr::select(-SUB_POP, -TOT_POP)
```

#### 2000-2010

```{r}
dem_00_10 <- dem_00_10 %>%
  map_df(bind_rows)

sapply(dem_00_10, class)

dem_00_10 <- dem_00_10 %>%
  dplyr::select(-ESTIMATESBASE2000,-CENSUS2010POP) %>%
  filter(REGION != 0,
         DIVISION != 0,
         SEX != 0,
         ORIGIN == 0,
         RACE != 0,
         AGEGRP != 0,
         STATE != 0) %>%
  dplyr::select(-REGION, -DIVISION, -ORIGIN, -STATE) %>%
  rename("STATE"=NAME,
         "AGE_GROUP"=AGEGRP) %>%
  mutate(SEX = factor(SEX,
                            levels = 1:2,
                            labels = c("Male",
                                    "Female")),
         RACE = factor(RACE,
                            levels = 1:6,
                            labels = c("White",
                                    "Black",
                                    rep("Other",4))),
         AGE_GROUP = factor(AGE_GROUP,
                            levels = 1:18,
                            labels = c("Under 5 years",
                                    "5 to 9 years",
                                    "10 to 14 years",
                                    "15 to 19 years",
                                    "20 to 24 years",
                                    "25 to 29 years",
                                    "30 to 34 years",
                                    "35 to 39 years",
                                    "40 to 44 years",
                                    "45 to 49 years",
                                    "50 to 54 years",
                                    "55 to 59 years",
                                    "60 to 64 years",
                                    "65 to 69 years",
                                    "70 to 74 years",
                                    "75 to 79 years",
                                    "80 to 84 years",
                                    "85 years and over"))) %>%
  mutate(SEX = as.character(SEX),
         RACE = as.character(RACE),
         AGE_GROUP = as.character(AGE_GROUP))
  
colnames(dem_00_10)

dem_00_10 <- dem_00_10 %>%
  pivot_longer(cols=contains("ESTIMATE"),
               names_to = "YEAR",
               values_to = "SUB_POP")

dem_00_10 <- dem_00_10 %>%
  mutate(YEAR = str_sub(YEAR, start=-4)) %>%
  mutate(YEAR = as.numeric(YEAR))

sapply(dem_00_10, class)

pop_00_10 <- dem_00_10 %>%
  group_by(YEAR, STATE) %>%
  summarise(TOT_POP = sum(SUB_POP), .groups = "drop")

dem_00_10 %>%
  left_join(pop_00_10, by=c("YEAR", "STATE")) %>%
  group_by(YEAR, STATE) %>%
  mutate(PERC_SUB_POP = SUB_POP*100/TOT_POP) %>%
  summarise(perc_tot = sum(PERC_SUB_POP), .groups = "drop") %>%
  mutate(poss_error = case_when(abs(perc_tot - 100) > 0 ~ TRUE, 
                                TRUE ~ FALSE)) %>%
  group_by(poss_error) %>%
  tally()

dem_00_10 <- dem_00_10 %>%
  left_join(pop_00_10, by=c("YEAR", "STATE")) %>%
  mutate(PERC_SUB_POP = SUB_POP*100/TOT_POP) %>%
  dplyr::select(-SUB_POP, -TOT_POP)
```

#### 1977 - 2010

```{r}
setequal(colnames(dem_77_79),colnames(dem_80_89))
setequal(colnames(dem_80_89),colnames(dem_90_99))
setequal(colnames(dem_90_99),colnames(dem_00_10))

head(dem_77_79)
head(dem_80_89)
head(dem_90_99)
head(dem_00_10)

length(summary(as.factor(dem_77_79$AGE_GROUP)))
length(summary(as.factor(dem_80_89$AGE_GROUP)))
length(summary(as.factor(dem_90_99$AGE_GROUP)))
length(summary(as.factor(dem_00_10$AGE_GROUP)))

dem <- bind_rows(dem_77_79,
                 dem_80_89,
                 dem_90_99,
                 dem_00_10)
  
dem %>%
  filter(RACE == "Other") %>%
  group_by(YEAR) %>%
  tally() %>%
  summarise(years_data = n())

2010 - 1977 + 1
  
DONOHUE_AGE_GROUPS <- c("15 to 19 years",
                        "20 to 24 years",
                        "25 to 29 years",
                        "30 to 34 years",
                        "35 to 39 years")

DONOHUE_RACE <- c("White",
                  "Black",
                  "Other")

DONOHUE_SEX <- c("Male")

dem_DONOHUE <- dem %>%
  filter(AGE_GROUP %in% DONOHUE_AGE_GROUPS,
         RACE %in% DONOHUE_RACE,
         SEX %in% DONOHUE_SEX) %>%
  mutate(AGE_GROUP = fct_collapse(AGE_GROUP, "20 to 39 years"=c("20 to 24 years",
                                                                "25 to 29 years",
                                                                "30 to 34 years",
                                                                "35 to 39 years"))) %>%
  mutate(AGE_GROUP = str_replace_all(AGE_GROUP," ","_")) %>%
  group_by(YEAR, STATE, RACE, SEX, AGE_GROUP) %>%
  summarise(PERC_SUB_POP = sum(PERC_SUB_POP), .groups = "drop") %>%
  unite(col = "VARIABLE", RACE, SEX, AGE_GROUP, sep = "_") %>%
  rename("VALUE"=PERC_SUB_POP)

LOTT_AGE_GROUPS_NULL <- c("Under 5 years",
                          "5 to 9 years")

LOTT_RACE <- c("White",
               "Black",
               "Other")

LOTT_SEX <- c("Male",
              "Female")

dem_LOTT <- dem %>%
  filter(!(AGE_GROUP %in% LOTT_AGE_GROUPS_NULL),
         RACE %in% LOTT_RACE,
         SEX %in% LOTT_SEX) %>%
  mutate(AGE_GROUP = fct_collapse(AGE_GROUP,
                                  "10 to 19 years"=c("10 to 14 years",
                                                     "15 to 19 years"),
                                  "20 to 29 years"=c("20 to 24 years",
                                                     "25 to 29 years"),
                                  "30 to 39 years"=c("30 to 34 years",
                                                     "35 to 39 years"),
                                  "40 to 49 years"=c("40 to 44 years",
                                                     "45 to 49 years"),
                                  "50 to 64 years"=c("50 to 54 years",
                                                     "55 to 59 years",
                                                     "60 to 64 years"),
                                  "65 years and over"=c("65 to 69 years",
                                                        "70 to 74 years",
                                                        "75 to 79 years",
                                                        "80 to 84 years",
                                                        "85 years and over"))) %>%
  mutate(AGE_GROUP = str_replace_all(AGE_GROUP," ","_")) %>%
  group_by(YEAR, STATE, RACE, SEX, AGE_GROUP) %>%
  summarise(PERC_SUB_POP = sum(PERC_SUB_POP), .groups = "drop") %>%
  unite(col = "VARIABLE", RACE, SEX, AGE_GROUP, sep = "_") %>%
  rename("VALUE"=PERC_SUB_POP)
  
dim(expand.grid(c(1:6), c(7:8), c(9:10)))[1]
```

```{r}
setequal(colnames(pop_77_79),colnames(pop_80_89))
setequal(colnames(pop_80_89),colnames(pop_90_99))
setequal(colnames(pop_90_99),colnames(pop_00_10))

head(pop_77_79)
head(pop_80_89)
head(pop_90_99)
head(pop_00_10)

population_data <- bind_rows(pop_77_79,
                             pop_80_89,
                             pop_90_99,
                             pop_00_10)

population_data %>%
  group_by(YEAR) %>%
  tally() %>%
  print(n = dim(.)[1])

population_data <- population_data %>%
  mutate(VARIABLE = "Population") %>%
  rename("VALUE"=TOT_POP)
```

## Police staffing


```{r}
colnames(ps_data)

ps_data <- ps_data %>%
  filter(data_year >= 1977, 
         data_year <= 2014) %>%
  mutate(male_total_ct = case_when(is.na(male_total_ct) ~ 0,
                                   TRUE ~ male_total_ct),
         female_total_ct = case_when(is.na(female_total_ct) ~ 0,
                                   TRUE ~ female_total_ct)) %>%
  mutate(officer_total = male_total_ct + female_total_ct) %>%
  dplyr::select(data_year,
                pub_agency_name,
                state_abbr,
                officer_total)

ps_data <- ps_data %>%
  group_by(data_year, state_abbr) %>%
  summarise(officer_state_total=sum(officer_total), .groups = "drop")

ps_data %>%
  group_by(state_abbr) %>%
  tally() %>%
  print(n = dim(.)[1])

# NB is Nebraska. This was changed to NE to avoid confusions with NB in Canada. This dataset uses NB

state_of_interest_NULL <- c("AS",
                            "GM",
                            "CZ",
                            "FS",
                            "MP",
                            "OT",
                            "PR",
                            "VI")

state_abb_df <- as.data.frame(cbind(state.abb, state.name))

colnames(state_abb_df) <- c("state_abbr", "STATE")

print(state_abb_df)

state_abb_df <- state_abb_df %>%
  add_row(state_abbr="DC",
          STATE="District of Columbia")

denominator_temp <- population_data %>%
  dplyr::select(-VARIABLE) %>%
  rename("Population_temp"=VALUE)

ps_data <- ps_data %>%
  filter(!(state_abbr %in% state_of_interest_NULL)) %>%
  mutate(state_abbr = case_when(state_abbr == "NB" ~ "NE",
                                TRUE ~ state_abbr)) %>%
  left_join(state_abb_df, by = "state_abbr") %>%
  dplyr::select(-state_abbr) %>%
  rename(YEAR = "data_year",
         VALUE = "officer_state_total") %>%
  mutate(VARIABLE = "officer_state_total") %>%
  left_join(denominator_temp, by=c("STATE","YEAR")) %>%
  mutate(VALUE = (VALUE*100000) / Population_temp) %>%
  mutate(VALUE = lag(VALUE)) %>%
  mutate(VARIABLE = "police_per_100k_lag") %>%
  dplyr::select(-Population_temp)
```

## Unemployment


```{r}


names(ue_rate_data) <- ue_rate_names

ue_rate_data$Alabama[dim(ue_rate_data$Alabama)[1],]

ue_rate_data <- ue_rate_data %>%
  map_df(bind_rows, .id = "STATE")

colnames(ue_rate_data)

sapply(ue_rate_data, class)

ue_rate_data <- ue_rate_data %>%
  mutate(Year = as.numeric(Year)) %>%
  dplyr::select(STATE, Year, Annual) %>%
  rename("YEAR"=Year,
         "VALUE"=Annual) %>%
  mutate(VARIABLE="Unemployment_rate")
```

## Poverty rate


```{r}
head(poverty_rate_data)

colnames(poverty_rate_data) <- c("STATE",
                                 "Total",
                                 "Number",
                                 "Number_se",
                                 "Percent",
                                 "Percent_se")

tail(poverty_rate_data)

notes <- 4

poverty_rate_data <- poverty_rate_data[-((dim(poverty_rate_data)[1]-notes+1):dim(poverty_rate_data)[1]),]

states_eq <- 51

extra_col <- 2

rep_rows <- states_eq + extra_col

groups <- (dim(poverty_rate_data)[1])/(rep_rows)

paste(groups - (2018-1980 + 1), "extra groups")

poverty_rate_data$year_group <- rep(1:groups, each=rep_rows)

poverty_rate_data <- poverty_rate_data %>%
  group_by(year_group) %>%
  group_split()

head(poverty_rate_data[[1]])

poverty_rate_data <- poverty_rate_data %>%
  map(~mutate(.,
              row_id = row_number())) %>%
  map(~filter(.,row_id != 2)) %>%
  map(~dplyr::select(.,-row_id))

poverty_rate_data_names <- poverty_rate_data %>%
  sapply(., "[",1,1, drop=TRUE) %>%
  str_replace_all(.,"[:space:]","_")

names(poverty_rate_data) <- poverty_rate_data_names

# Recall 2 extra groups. 
# footnotes available at https://www.census.gov/topics/income-poverty/poverty/guidance/poverty-footnotes/cps-historic-footnotes.html

poverty_rate_data$`2017_(21)` <- NULL

poverty_rate_data$`2013_(19)` <- NULL

poverty_rate_data_names <- poverty_rate_data %>%
  sapply(., "[",1,1, drop=TRUE) %>%
  str_sub(., start = 1, end=4)

names(poverty_rate_data) <- poverty_rate_data_names

poverty_rate_data <- poverty_rate_data %>%
  map_df(bind_rows, .id = "YEAR") %>%
  dplyr::select(-year_group)

poverty_rate_data <- poverty_rate_data %>%
    mutate(n_na = rowSums(is.na(.))) 

# This shows that there is systematic missing values stemmingly *solely* from the rows without poverty data and only a label designating the year
poverty_rate_data %>% 
  group_by(n_na) %>%
  tally()

sapply(poverty_rate_data, class)

poverty_rate_data <- poverty_rate_data %>%
  drop_na() %>%
  dplyr::select(-Number,
                -Number_se,
                -Percent_se,
                -n_na,
                -Total) %>%
  rename("VALUE"=Percent) %>%
  mutate(VARIABLE = "Poverty_rate",
         YEAR = as.numeric(YEAR),
         VALUE = as.numeric(VALUE))

colnames(poverty_rate_data)
```

## Violent crime

https://www.ucrdatatool.gov/Search/Crime/State/StatebyState.cfm

```{r}
crime_data <- read_lines("docs/Crime/CrimeStatebyState.csv", skip = 2, skip_empty_rows = TRUE)

length(crime_data)

crime_data <- crime_data[-(2143:length(crime_data))]

x <- 2014-1977+1

rep_cycle <- 2 + 2 + x

rep_cycle_cut <- 2 + x

delete_rows <- c(seq(2,length(crime_data),rep_cycle),
                 seq(3,length(crime_data),rep_cycle))

crime_data <- crime_data[-delete_rows]

crime_data <- data.frame(cbind(crime_data, rep(1:(length(crime_data)/rep_cycle_cut),each=rep_cycle_cut)))

colnames(crime_data) <- c("String","STATE_GROUP")

crime_data <- crime_data %>%
  group_by(STATE_GROUP) %>%
  group_split()

columns_crime_data <- 8

crime_data <- crime_data %>%
  map(~mutate(.,
               State = case_when(str_detect(String, "Estimated crime in ") ~ substring(String, nchar("Estimated crime in ")+1)),
              row_id = row_number())) %>%
  map(~fill(., State)) %>%
  map(~filter(.,row_id > 2)) %>%
  map(~mutate(.,
              String = paste0(String, ",", State))) %>%
  map(~dplyr::select(.,String)) %>%
  map(~str_split_fixed(.$String,",",columns_crime_data + 1)) %>%
  map(~data.frame(.)) %>%
  map(~rename(.,"YEAR"=X1,
              "Extra_col1"=X2,
              "VC"=X3,
              "Extra_col2"=X4,
              "Extra_col3"=X5,
              "Extra_col4"=X6,
              "Extra_col5"=X7,
              "Extra_col6"=X8,
              "STATE"=X9)) %>%
  map(~dplyr::select(.,-contains("Extra_col"))) %>%
  map(~.x %>% mutate_all(~trimws(.,which = "both"))) %>%
  map_df(bind_rows)

sapply(crime_data, class)

crime_data <- crime_data %>%
  mutate(VARIABLE = "Viol_crime_count") %>%
  rename("VALUE" = VC) %>%
  as.tibble() %>%
  mutate(YEAR = as.numeric(YEAR),
         VALUE = as.numeric(VALUE))
```

## RTC laws


```{r}
DAWpaper_p_62 <- DAWpaper[[62]]

p_62 <- DAWpaper_p_62 %>%
    strsplit("\n") %>%
    unlist() %>%
    as.data.frame() %>%
    slice(-(1:2))

apply(p_62, 1, nchar)

p_62[53,] #physcial page 60

p_62 <- p_62 %>%
    slice(-53)

apply(p_62, 1, str_count, "\\s{5,}")
apply(p_62, 1, str_count, "\\s{10,}")
apply(p_62, 1, str_count, "\\s{20,}")
apply(p_62, 1, str_count, "\\s{40,}")

head(cbind(p_62, apply(p_62, 1, str_count, "\\s{40,}")))

p_62 <- p_62 %>%
    apply(1,str_replace_all, "\\s{40,}", "|N/A|") %>%
    str_replace_all("\\s{2,15}", "|") %>%
    as.data.frame()

p_62 <- sapply(p_62$., str_split, "\\|{1,}")

sapply(p_62, nchar)

p_62 <- lapply(p_62, function(x) x[nchar(x) > 0]) 

p_62 <- as.data.frame(do.call(rbind, p_62))

rownames(p_62)

rownames(p_62) <- c()

colnames(p_62) <- c("STATE",
                    "E_Date_RTC",
                    "Frac_Yr_Eff_Yr_Pass",
                    "RTC_Date_SA")
sapply(p_62, class)

p_62 <- p_62 %>%
  dplyr::select(STATE, RTC_Date_SA) %>%
  rename("RTC_LAW_YEAR"=RTC_Date_SA) %>%
  mutate(RTC_LAW_YEAR = as.numeric(RTC_LAW_YEAR)) %>%
  mutate(RTC_LAW_YEAR = case_when(RTC_LAW_YEAR == 0 ~ Inf,
                              TRUE ~ RTC_LAW_YEAR))

sapply(p_62, class)

head(p_62)
```

## Checkpoint

```{r}
colnames(dem_DONOHUE)
colnames(dem_LOTT)
colnames(ue_rate_data)
colnames(poverty_rate_data)
colnames(crime_data)

head(dem_DONOHUE)
head(dem_LOTT)
head(ue_rate_data)
head(poverty_rate_data)
head(crime_data)
```

## Join

## Donohue, et al.

```{r}
DONOHUE_DF <- bind_rows(dem_DONOHUE,
                        ue_rate_data,
                        poverty_rate_data,
                        crime_data,
                        population_data,
                        ps_data) %>%
  pivot_wider(names_from = "VARIABLE",
              values_from = "VALUE") %>%
  left_join(p_62 , by = c("STATE")) %>%
  mutate(RTC_LAW = case_when(YEAR >= RTC_LAW_YEAR ~ TRUE,
                              TRUE ~ FALSE))

DONOHUE_DF %>%
  group_by(YEAR) %>%
  tally() %>%
  filter(n != 51) %>%
  print(n=dim(.)[1])

summary(as.factor(DONOHUE_DF$STATE))

max(DONOHUE_DF$YEAR) - min(DONOHUE_DF$YEAR) + 1

DONOHUE_DF <- DONOHUE_DF %>%
  mutate(STATE = fct_collapse(STATE, "District of Columbia"=c("District of Columbia","D.C.")))

summary(as.factor(DONOHUE_DF$STATE))
  
length(levels(DONOHUE_DF$STATE))

DONOHUE_DF <- DONOHUE_DF %>%
  group_by(STATE, YEAR) %>%
  summarise_all(~na.omit(unique(.))) %>%
  ungroup() # This identifies unique observations, coalesces rows according to the grouping variable(s), and gets rid of of units that have incomplete data. This gives returns a dataframe with the most complete information.

summary(as.factor(DONOHUE_DF$STATE)) 

baseline_year <- min(DONOHUE_DF$YEAR)
censoring_year <- max(DONOHUE_DF$YEAR)

# Need to fix this to ensure severe bias is not introduced by prevalent "cases"

DONOHUE_DF <- DONOHUE_DF %>%
  mutate(TIME_0 = baseline_year,
         TIME_INF = censoring_year) %>%
  filter(RTC_LAW_YEAR > TIME_0)

DONOHUE_DF <- DONOHUE_DF %>%
  mutate(Viol_crime_rate_1k = (Viol_crime_count*1000)/Population,
         Viol_crime_rate_1k_log = log(Viol_crime_rate_1k),
         Population_log = log(Population))

summary(droplevels(as.factor(DONOHUE_DF$STATE)))

length(summary(droplevels(as.factor(DONOHUE_DF$STATE))))
```

## Lott and Mustard

```{r}
LOTT_DF <- bind_rows(dem_LOTT,
                     ue_rate_data,
                     poverty_rate_data,
                     crime_data,
                     population_data,
                     ps_data) %>%
  pivot_wider(names_from = "VARIABLE",
              values_from = "VALUE") %>%
  left_join(p_62 , by = c("STATE")) %>%
  mutate(RTC_LAW = case_when(YEAR >= RTC_LAW_YEAR ~ TRUE,
                              TRUE ~ FALSE))

LOTT_DF %>%
  group_by(YEAR) %>%
  tally() %>%
  filter(n != 51) %>%
  print(n=dim(.)[1])

summary(as.factor(LOTT_DF$STATE))

max(LOTT_DF$YEAR) - min(LOTT_DF$YEAR) + 1

LOTT_DF <- LOTT_DF %>%
  mutate(STATE = fct_collapse(STATE, "District of Columbia"=c("District of Columbia","D.C.")))

summary(as.factor(LOTT_DF$STATE))
  
length(levels(LOTT_DF$STATE))

LOTT_DF <- LOTT_DF %>%
  group_by(STATE, YEAR) %>%
  summarise_all(~na.omit(unique(.))) %>%
  ungroup() # This identifies unique observations, coalesces rows according to the grouping variable(s), and gets rid of of units that have incomplete data. This gives returns a dataframe with the most complete information.

summary(as.factor(LOTT_DF$STATE)) 

baseline_year <- min(LOTT_DF$YEAR)
censoring_year <- max(LOTT_DF$YEAR)

# Need to fix this to ensure severe bias is not introduced by prevalent "cases"

LOTT_DF <- LOTT_DF %>%
  mutate(TIME_0 = baseline_year,
         TIME_INF = censoring_year) %>%
  filter(RTC_LAW_YEAR > TIME_0)

LOTT_DF <- LOTT_DF %>%
  mutate(Viol_crime_rate_1k = (Viol_crime_count*1000)/Population,
         Viol_crime_rate_1k_log = log(Viol_crime_rate_1k),
         Population_log = log(Population))

summary(droplevels(as.factor(LOTT_DF$STATE)))

length(summary(droplevels(as.factor(LOTT_DF$STATE))))
```

# **Data Exploration**
***

```{r}
sapply(DONOHUE_DF, class)

DONOHUE_DF %>%
  mutate(Viol_crime_rate_100k_log = log((Viol_crime_count*100000)/Population)) %>%
  ggplot(aes(x = YEAR, y = Viol_crime_rate_100k_log, color = STATE)) +
  geom_point(size = 0.5) +
  geom_line(aes(group=STATE),
            size = 0.5,
            show.legend = FALSE) +
  geom_text_repel(data = DONOHUE_DF %>%
              mutate(Viol_crime_rate_100k_log = log((Viol_crime_count*100000)/Population)) %>%
              filter(YEAR == last(YEAR)),
            aes(label = STATE,
                x = YEAR,
                y = Viol_crime_rate_100k_log),
            size = 3,
            alpha = 1,
            nudge_x = 10,
            direction = "y",
            hjust = 1,
            vjust = 1,
            segment.size = 0.25,
            segment.alpha = 0.25,
            force = 1,
            max.iter = 9999) +
  guides(color = FALSE) +
  scale_x_continuous(breaks = seq(1980, 2015, by = 1),
                     limits = c(1980, 2015),
                     labels = c(seq(1980, 2010, by = 1), rep("", 5))) +
  scale_y_continuous(breaks = seq(3.5, 8.5, by = 0.5),
                     limits = c(3.5, 8.5)) +
  labs(title = "States have different levels of crime",
       x = "Year",
       y = "ln(violent crimes per 100,000 people)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90))

DONOHUE_DF %>%
  group_by(YEAR) %>%
  summarise(Viol_crime_count = sum(Viol_crime_count),
            Population = sum(Population),
            .groups = "drop") %>%
  mutate(Viol_crime_rate_100k_log = log((Viol_crime_count*100000)/Population)) %>%
  ggplot(aes(x = YEAR, y = Viol_crime_rate_100k_log)) +
  geom_line() +
  scale_x_continuous(breaks = seq(1980, 2010, by = 1),
                     limits = c(1980, 2010),
                     labels = c(seq(1980, 2010, by = 1))) +
  scale_y_continuous(breaks = seq(5.75, 6.75, by = 0.25),
                     limits = c(5.75, 6.75)) +
  labs(title = "Crime rates fluctuate over time",
       x = "Year",
       y = "ln(violent crimes per 100,000 people)") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 90))
```

# **Data Analysis**
***

## Donohue, et al.

Some code taken from http://karthur.org/2019/implementing-fixed-effects-panel-models-in-r.html

```{r}
d_panel_DONOHUE <- pdata.frame(DONOHUE_DF, index=c("STATE", "YEAR"))

DONOHUE_OUTPUT <- plm(Viol_crime_rate_1k_log ~
                        RTC_LAW +
                        White_Male_15_to_19_years +
                        White_Male_20_to_39_years +
                        Black_Male_15_to_19_years +
                        Black_Male_20_to_39_years +
                        Other_Male_15_to_19_years +
                        Other_Male_20_to_39_years +
                        Unemployment_rate +
                        Poverty_rate + 
                        Population_log + 
                        police_per_100k_lag,
                      effect = "twoways",
                      model = "within",
                      data=d_panel_DONOHUE)

summary(DONOHUE_OUTPUT)

DONOHUE_OUTPUT_TIDY <- tidy(DONOHUE_OUTPUT, conf.int = 0.95)

DONOHUE_OUTPUT_TIDY$Analysis <- "Analysis 1"
```

## Lott and Mustard

Some code taken from http://karthur.org/2019/implementing-fixed-effects-panel-models-in-r.html

```{r}
LOTT_variables <- LOTT_DF %>%
  dplyr::select(RTC_LAW,
                contains(c("White","Black","Other")),
                Unemployment_rate,
                Poverty_rate,
                Population_log,
                police_per_100k_lag) %>%
  colnames()

LOTT_fmla <- as.formula(paste("Viol_crime_rate_1k_log ~",
                              paste(LOTT_variables, collapse = " + ")
                              )
                        )

d_panel_LOTT <- pdata.frame(LOTT_DF, index=c("STATE", "YEAR"))

LOTT_OUTPUT <- plm(LOTT_fmla,
                      model = "within",
                   effect = "twoways",
                      data=d_panel_LOTT)

summary(LOTT_OUTPUT)

LOTT_OUTPUT_TIDY <- tidy(LOTT_OUTPUT, conf.int = 0.95)

LOTT_OUTPUT_TIDY$Analysis <- "Analysis 2"
```

## Comparing analyses

```{r}
comparing_analyses <- DONOHUE_OUTPUT_TIDY %>%
  bind_rows(LOTT_OUTPUT_TIDY) %>%
  filter(term == "RTC_LAWTRUE")

library(grid)

comparing_analyses_plot <- ggplot(comparing_analyses) + 
  geom_point(aes(x = Analysis, y = estimate)) +
  geom_errorbar(aes(x = Analysis, ymin = conf.low, ymax = conf.high), width = 0.25) + 
  geom_hline(yintercept = 0, color = "red") +
  scale_y_continuous(breaks = seq(-0.2, 0.2, by = 0.05),
                     labels = seq(-0.2, 0.2, by = 0.05),
                     limits = c(-0.2,0.2)) +
  geom_segment(aes(x = 1, y = 0.125, xend = 1, yend = 0.175),
               arrow = arrow(angle = 45, ends = "last", type = "open"),
               size = 2,
               color = "green",
               lineend = "butt",
               linejoin = "mitre") +
  geom_segment(aes(x = 2, y = -0.125, xend = 2, yend = -0.175),
               arrow = arrow(angle = 45, ends = "last", type = "open"),
               size = 2,
               color = "red",
               lineend = "butt",
               linejoin = "mitre") +
  theme_minimal() + 
  theme(axis.title.x = element_blank(),
        axis.text = element_text(size = 12)) +
  labs(title = "Effect estimate on ln(violent crimes per 100,000 people)",
       y = "Effect estimate (95% CI)")

comparing_analyses_plot
```

# Multicollinearity analysis

How did the above happen?

The analysis dataframes are very similar yet rendered very different results. 

```{r}
all_equal(target = DONOHUE_DF,
          current = LOTT_DF,
          ignore_col_order = TRUE,
          ignore_row_order = TRUE)

dim(DONOHUE_DF)[1] == dim(LOTT_DF)[1]
```

The only difference between the two dataframes rests in how the demographic variables were parameterized.

```{r}
DONOHUE_DF %>%
  dplyr::select(contains("years")) %>%
  colnames()

LOTT_DF %>%
  dplyr::select(contains("years")) %>%
  colnames()
```

Clearly, this had an effect on the results of the analysis. 

Let's explore how this occured. 

When seemingly independent variables are highly related to one another, the relationships estimated in an analysis may be distorted. 

In regression analysis, this distortion is often a byproduct of a violation of the independence assumption. This distortion, if large enough, can impact statistical inference. 

There are several ways we can diagnose multicollinearity.

### Correlation

Again, multicollinearity often occurs when independent variables are highly related to one another. Consequently, we can evaluate these relationships be examining the correlation between variable pairs.

<style>
div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 20px;}
</style>
<div class = "blue">

It is important to note that multicollinearity and correlation are not one and the same. Correlation can be thought of as the strength of the relationship between variables. On the other hand, multicollinearity can be thought of the the violation of the independence assumption that is a consequence of this correlation in a regression analysis. 

</div>

#### Scatterplots

```{r}
colnames(DONOHUE_DF)

DONOHUE_DF %>% 
  dplyr::select(RTC_LAW,
                Viol_crime_rate_1k_log,
                Unemployment_rate,
                Poverty_rate,
                Population_log) %>% 
  ggpairs(.,
          columns = c(2:5),
          lower = list(continuous = wrap("smooth_loess",
                                         color = "red",
                                         alpha = 0.5,
                                         size = 0.1)))

LOTT_DF %>% 
  dplyr::select(RTC_LAW,
                Viol_crime_rate_1k_log,
                Unemployment_rate,
                Poverty_rate,
                Population_log) %>% 
  ggpairs(.,
          columns = c(2:5),
          lower = list(continuous = wrap("smooth_loess",
                                         color = "red",
                                         alpha = 0.5,
                                         size = 0.1)))
```

#### Heatmaps

```{r}
cor_DONOHUE_dem <- cor(DONOHUE_DF %>% dplyr::select(contains("_years")))

corr_mat_DONOHUE <- ggcorrplot(cor_DONOHUE_dem,
           tl.cex = 6,
           hc.order = TRUE,
           colors = c("red",
                      "white",
                      "red"),
           outline.color = "transparent",
           title = "Correlation Matrix, Analysis 1",
           legend.title = TeX("$\\rho$"))

corr_mat_DONOHUE

cor_LOTT_dem <- cor(LOTT_DF %>% dplyr::select(contains("_years")))

corr_mat_LOTT <- ggcorrplot(cor_LOTT_dem,
           tl.cex = 6,
           hc.order = TRUE,
           colors = c("red",
                      "white",
                      "red"),
           outline.color = "transparent",
           title = "Correlation Matrix, Analysis 2",
           legend.title = TeX("$\\rho$"))

corr_mat_LOTT
```

### Coefficient estimate instability

```{r}
sims <- 250

# DONOHUE

# round(dim(DONOHUE_DF)[1]/2)
samps_DONOHUE <- lapply(rep(dim(DONOHUE_DF)[1]-1, sims),
       function(x)DONOHUE_DF[sample(nrow(DONOHUE_DF),
                                     size = x, replace = FALSE),])

fit_nls_on_bootstrap_DONOHUE <- function(split){
  plm(Viol_crime_rate_1k_log ~
                        RTC_LAW +
                        White_Male_15_to_19_years +
                        White_Male_20_to_39_years +
                        Black_Male_15_to_19_years +
                        Black_Male_20_to_39_years +
                        Other_Male_15_to_19_years +
                        Other_Male_20_to_39_years +
                        Unemployment_rate +
                        Poverty_rate + 
                        Population_log + 
                        police_per_100k_lag,
      data = data.frame(split),
      index = c("STATE","YEAR"),
      model = "within",
      effect = "twoways")
}
  
samps_models_DONOHUE <- lapply(samps_DONOHUE, fit_nls_on_bootstrap_DONOHUE)

samps_models_DONOHUE <- samps_models_DONOHUE %>%
  map(tidy)

names(samps_models_DONOHUE) <- paste0("DONOHUE_",1:length(samps_models_DONOHUE))

simulations_DONOHUE <- samps_models_DONOHUE %>%
  bind_rows(.id = "ID") %>%
  mutate(Analysis = "Analysis 1")

## LOTT

samps_LOTT <- lapply(rep(round(dim(LOTT_DF)[1]/2), sims),
       function(x) LOTT_DF[sample(nrow(LOTT_DF),
                                  size = x, replace = FALSE),])

fit_nls_on_bootstrap_LOTT <- function(split){
  plm(LOTT_fmla,
      data = data.frame(split),
      index = c("STATE","YEAR"),
      model = "within",
      effect = "twoways")
}
  
samps_models_LOTT <- lapply(samps_LOTT, fit_nls_on_bootstrap_LOTT)

samps_models_LOTT <- samps_models_LOTT %>%
  map(tidy)

names(samps_models_LOTT) <- paste0("LOTT_",1:length(samps_models_LOTT))

simulations_LOTT <- samps_models_LOTT %>%
  bind_rows(.id = "Analysis") %>%
  mutate(Analysis = "Analysis 2")

simulations <- bind_rows(simulations_DONOHUE,
                         simulations_LOTT)

simulation_plot <- simulations %>%
  filter(term=="RTC_LAWTRUE") %>%
  ggplot(aes(x = Analysis, y = estimate)) + 
  geom_jitter(alpha = 0.25,
              width = 0.1) + 
  labs(title = "Coefficient instability",
       subtitle = "Estimates sensitive to observation deletions",
       x = "Term",
       y = "Coefficient",
       caption = "Results from simulations") + 
  theme_minimal() +
  theme(axis.title.x = element_blank())

simulation_plot
```

### VIF

```{r}
design.matrix <- as.data.frame(model.matrix(DONOHUE_OUTPUT))

design.matrix$Viol_crime_rate_1k_log <- plm::Within(
  d_panel_DONOHUE$Viol_crime_rate_1k_log)

lm_DONOHUE <- lm(Viol_crime_rate_1k_log ~
                        RTC_LAWTRUE + # logical class changes variable name after inital model
                        White_Male_15_to_19_years +
                        White_Male_20_to_39_years +
                        Black_Male_15_to_19_years +
                        Black_Male_20_to_39_years +
                        Other_Male_15_to_19_years +
                        Other_Male_20_to_39_years +
                        Unemployment_rate +
                        Poverty_rate + 
                        Population_log +
               police_per_100k_lag,
             data = design.matrix)


vif(lm_DONOHUE)

vif_DONOHUE <- vif(lm_DONOHUE)

vif_DONOHUE <- vif_DONOHUE %>%
  as_tibble() %>%
  cbind(., names(vif_DONOHUE)) %>%
  as_tibble()
  
colnames(vif_DONOHUE) <- c("VIF", "Variable")

max_vif_DONOHUE <- max(vif(lm_DONOHUE)) 
```

```{r}
design.matrix <- as.data.frame(model.matrix(LOTT_OUTPUT))

design.matrix$Viol_crime_rate_1k_log <- plm::Within(
  d_panel_LOTT$Viol_crime_rate_1k_log)

LOTT_variables_ols <- LOTT_DF %>%
  dplyr::select(RTC_LAW,
                contains(c("White","Black","Other")),
                Unemployment_rate,
                Poverty_rate,
                Population_log,
                police_per_100k_lag) %>%
  colnames() %>%
  str_replace("RTC_LAW", "RTC_LAWTRUE") # logical class changes variable name after inital model

LOTT_fmla_ols <- as.formula(paste("Viol_crime_rate_1k_log ~",
                              paste(LOTT_variables_ols, collapse = " + ")
                              )
                        )

lm_LOTT <- lm(LOTT_fmla_ols,
             data = design.matrix)

vif(lm_LOTT)

vif_LOTT <- vif(lm_LOTT)

vif_LOTT <- vif_LOTT %>%
  as_tibble() %>%
  cbind(., names(vif_LOTT)) %>%
  as_tibble()
  
colnames(vif_LOTT) <- c("VIF", "Variable")

max_vif_LOTT <- max(vif(lm_LOTT))
```

```{r, echo=FALSE}
#This could be used to label the max VIF of each analysis

max_vif_DONOHUE
max_vif_LOTT
```

$$\frac{1}{1-R_{i}^{2}}$$

```{r}
vif_DONOHUE$Analysis <- "Analysis 1"
vif_LOTT$Analysis <- "Analysis 2"

vif_df <- rbind(vif_DONOHUE,
                vif_LOTT)

vif_plot <- vif_df %>%
  ggplot(aes(x = Analysis, y = VIF)) +
  geom_jitter(width = 0.1, alpha = 0.5, size = 2) +
  geom_hline(yintercept = 10, color = "red") +
  scale_y_continuous(trans = 'log10',
                     limits = c(1,1000)) +
  labs(title = "Variance inflation factors") + 
  theme_minimal() +
  theme(axis.title.x = element_blank())

vif_plot
```

# Synthesis

```{r, fig.height=10, echo=FALSE, message=FALSE, warning=FALSE}
title_plots <- ggdraw() + 
  draw_label(
    "Multicollinearity and its effects",
    fontface = 'bold',
    size=18,
    x = 0,
    hjust = 0
  ) +
  theme(
    plot.margin = margin(0, 0, 0, 0)
  )

forward <- ggdraw() + 
  draw_label(
    "Analysis 1: 6 demographic variables\nAnalysis 2: 36 demographic variables",
    fontface = 'bold',
    size=10,
    x = 0,
    hjust = 0
  ) +
  theme(
    plot.margin = margin(0, 0, 0, 0)
  )

corr_mat_DONOHUE <- ggcorrplot(cor_DONOHUE_dem,
                               tl.cex = 6,
                               hc.order = TRUE,
                               outline.color = "transparent",
                               colors = c("red",
                                          "white",
                                          "red"),
                            legend.title = TeX("$\\rho$")) +
  theme_void() + 
  theme(plot.title= element_text(size=8)) +
  labs(title = "Analysis 1") 

corr_mat_LOTT <- ggcorrplot(cor_LOTT_dem,
                            tl.cex = 6,
                            hc.order = TRUE,
                            outline.color = "transparent",
                            colors = c("red",
                                       "white",
                                       "red"),
                            legend.title = TeX("$\\rho$")) +
  theme_void() + 
  theme(plot.title = element_text(size=8)) +
  labs(title = "Analysis 2") 

plot_A1 <- corr_mat_DONOHUE

plot_A2 <- corr_mat_LOTT

row_A <- plot_grid(plot_A1,
                   plot_A2,
                   nrow = 1)

title_A <- ggdraw() + 
  draw_label(
    "Correlation between variables can induce multicollinearity",
    fontface = 'bold',
    size=14,
    x = 0,
    hjust = 0
  ) +
  theme(
    plot.margin = margin(0, 0, 0, 0)
  )

legend_A <- get_legend(corr_mat_LOTT)

plot_A <- plot_grid(title_A,
                    row_A,
                    ncol = 1,
                    rel_heights = c(0.1,1))

empty_df <- cbind(c(1:10),c(1:10)) %>%
  as.data.frame()

colnames(empty_df) <- c("X", "Y")

plot_B1 <- ggplot(empty_df, aes(x = X, y = Y)) +
  annotate("text",
           x=5,
           y=5,
           label = TeX("$VIF_{i} = \\frac{1}{1-R_{i}^{2}}$"),
           size = 8) +
  theme_void()

plot_B2 <- vif_plot +
  theme(axis.title.x = element_text(size=8))

row_B <- plot_grid(plot_B1,
                       plot_B2,
                       nrow = 1)

title_B <- ggdraw() + 
  draw_label(
    "Variance inflation factors can be used to identify multicollinearity when present",
    fontface = 'bold',
    size=14,
    x = 0,
    hjust = 0
  ) +
  theme(
    plot.margin = margin(0, 0, 0, 0)
  )

plot_B <- plot_grid(title_B,
                    row_B,
                    ncol = 1,
                    rel_heights = c(0.1,1))

plot_C1 <- comparing_analyses_plot + 
  theme(axis.text.x = element_text(size = 8),
        axis.title.x = element_blank()) +
  labs(title = "Introduces bias to estimates",
       subtitle = "Bias introduced can change direction of estimate")

plot_C2 <- simulation_plot +
  labs(title = "Reduces precision in estimates")

row_C <- plot_grid(plot_C1,
                       plot_C2,
                       nrow = 1)

title_C <- ggdraw() + 
  draw_label(
    "Multicollinearity can have a negative effect on statistical inference",
    fontface = 'bold',
    size=14,
    x = 0,
    hjust = 0
  ) +
  theme(
    plot.margin = margin(0, 0, 0, 0)
  )

plot_C <- plot_grid(title_C,
                    row_C,
                    ncol = 1,
                    rel_heights = c(0.1,1))

plots <- plot_grid(plot_A,
                   plot_B,
                   plot_C,
          ncol = 1,
          rel_heights = c(1,1,1))

mainplot <- plot_grid(title_plots,
                       forward,
                       plots,
                       #legend_uw,
                       ncol = 1,
                       rel_heights = c(0.05,
                                       0.05,
                                       1))

mainplot
```



```{r, echo=FALSE, include=FALSE}
ggsave(here::here("img", "mainplot.png"))
```




# **Data Visualization**
*** 

# **Summary**
*** 

# **Suggested Homework**
*** 

# **Helpful Links**
*** 

https://rpubs.com/rslbliss/fixed_effects

http://karthur.org/2019/implementing-fixed-effects-panel-models-in-r.html

https://stats.stackexchange.com/questions/99236/effects-in-panel-models-individual-time-or-twoways

